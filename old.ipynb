{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Farm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6419,
     "status": "ok",
     "timestamp": 1678136587358,
     "user": {
      "displayName": "Dinis Costa",
      "userId": "15980086246020437495"
     },
     "user_tz": 0
    },
    "hidden": true,
    "id": "MEE_zHnOw7sv",
    "outputId": "16b9613e-6dd5-4a6d-ce98-b474416d2c81"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from random import sample\n",
    "from traceback import print_tb\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 200\n",
    "TRAIN_PROP = 0.6\n",
    "VAL_PROP = 0.2\n",
    "TEST_PROP = 0.2\n",
    "dir='.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19031,
     "status": "ok",
     "timestamp": 1678136606386,
     "user": {
      "displayName": "Dinis Costa",
      "userId": "15980086246020437495"
     },
     "user_tz": 0
    },
    "id": "02Cxcozdw9qi",
    "jp-MarkdownHeadingCollapsed": true,
    "outputId": "97422448-f86b-4530-df99-e39d24d44db5"
   },
   "source": [
    "## Auxiliar Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(train_size=0.6, val_size=0.2, test_size=0.2):\n",
    "    dataset = list(range(DATASET_SIZE))\n",
    "    test_files = [int(file.split('.')[0]) for file in os.listdir(os.path.join(dir, \"dataset/official/test\")) if file != \"classes.txt\"]\n",
    "\n",
    "    train_val_size = int((train_size + val_size) * len(dataset))\n",
    "    val_size = int(val_size * len(dataset))\n",
    "    dataset = [num for num in dataset if num not in test_files]\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_val = sample(dataset, train_val_size)\n",
    "    val = sample(train_val, val_size)\n",
    "    train = [num for num in train_val if num not in val]\n",
    "    \n",
    "    return train, val\n",
    "\n",
    "def rm_from_dir():\n",
    "    base_path = os.path.join(dir, 'dataset/run')\n",
    "    for split in ['train', 'test', 'val']:\n",
    "        split_path = os.path.join(base_path, split)\n",
    "        for file in os.listdir(split_path):\n",
    "            file_path = os.path.join(split_path, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "\n",
    "def get_avg_conf(file_path, mode='confidence'):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            if mode == 'count':\n",
    "                return len(lines)\n",
    "            total_conf = sum(float(line.strip().split()[5]) for line in lines)\n",
    "            return total_conf / len(lines) if lines else 0\n",
    "    except Exception:\n",
    "        return 0 if mode in ['confidence', 'count'] else 1\n",
    "    \n",
    "    \n",
    "def avg_conf(mode='RANDOM', AL_mode = 'confidence', project='batch', name='name_batch'):\n",
    "    train_dir = os.path.join(dir, 'dataset/run/train')\n",
    "    val_dir = os.path.join(dir, \"dataset/run/val\")\n",
    "    train = [file for file in os.listdir(train_dir) if file.endswith('.jpg')]\n",
    "    val = [file for file in os.listdir(val_dir) if file.endswith('.jpg')]\n",
    "    \n",
    "    train_val_images_dir = os.path.join(dir, 'dataset/train_val_images')\n",
    "    to_eval = [file[:-4] for file in os.listdir(train_val_images_dir) if file not in train and file not in val]\n",
    "    \n",
    "    if mode not in ['AL', 'APPROACH']:\n",
    "        return to_eval\n",
    "    \n",
    "    path = os.path.join(dir, project, name, 'labels')\n",
    "    evals = [(eval_, get_avg_conf(os.path.join(path, f'{eval_}.txt'), mode=mode)) for eval_ in to_eval]\n",
    "    evals.sort(key=lambda x: x[1])\n",
    "    \n",
    "    return [file[0] for file in evals]\n",
    "\n",
    "\n",
    "def new_batch(weights=\"''\", project=\"batch\", name=\"name_batch\", mode=\"RANDOM\", train_size=0.05, val_size=0.05, split_random=True, dataset=\"improved\"):\n",
    "    if mode in [\"AL\", \"APPROACH\"]:\n",
    "        detect(weights=weights, project=project, name=name, source=\"dataset/train_val_images/\")\n",
    "    \n",
    "    batch = avg_conf(mode=mode, project=project, name=name)\n",
    "    \n",
    "    if mode not in [\"AL\", \"APPROACH\"]:\n",
    "        batch = sample(batch, int(DATASET_SIZE * (train_size + val_size)))\n",
    "        train = batch[:int(DATASET_SIZE * train_size)]\n",
    "        val = batch[int(DATASET_SIZE * train_size):int(DATASET_SIZE * train_size) + int(DATASET_SIZE * val_size)]\n",
    "    else:\n",
    "        batch = batch[:int(DATASET_SIZE * (train_size + val_size))]\n",
    "        if split_random:\n",
    "            train = sample(batch, int(DATASET_SIZE * train_size))\n",
    "            val = [im for im in batch if im not in train]\n",
    "        else:\n",
    "            train = batch[:int(DATASET_SIZE * train_size)]\n",
    "            val = batch[int(DATASET_SIZE * train_size):int(DATASET_SIZE * train_size) + int(DATASET_SIZE * val_size)]\n",
    "    \n",
    "    train_dst_dir = os.path.join(dir, \"dataset/run/train\")\n",
    "    val_dst_dir = os.path.join(dir, \"dataset/run/val\")\n",
    "    official_dir = os.path.join(dir, \"dataset/official\", dataset)\n",
    "    \n",
    "    for file in train:\n",
    "        for file_type in ['.txt', '.jpg']:\n",
    "            src = os.path.join(official_dir, file + file_type)\n",
    "            dst = os.path.join(train_dst_dir, file + file_type)\n",
    "            shutil.copy(src, dst)\n",
    "    \n",
    "    for file in val:\n",
    "        for file_type in ['.txt', '.jpg']:\n",
    "            src = os.path.join(official_dir, file + file_type)\n",
    "            dst = os.path.join(val_dst_dir, file + file_type)\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "\n",
    "def split_dataset(dataset=\"improved\", train_split=[], val_split=[], test_split=[]):\n",
    "    rm_from_dir()\n",
    "    \n",
    "    def copy_files(file_list, split):\n",
    "        split_dir = os.path.join(dir, 'dataset/run', split)\n",
    "        for file in file_list:\n",
    "            for file_type in ['.jpg', '.txt']:\n",
    "                src = os.path.join(dir, 'dataset', dataset if split != 'test' else 'improved', f'{file}{file_type}')\n",
    "                dst = os.path.join(split_dir, f'{file}{file_type}')\n",
    "                shutil.copy(src, dst)\n",
    "    \n",
    "    copy_files(train_split, 'train')\n",
    "    copy_files(val_split, 'val')\n",
    "    copy_files(test_split, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9144,
     "status": "ok",
     "timestamp": 1678136615528,
     "user": {
      "displayName": "Dinis Costa",
      "userId": "15980086246020437495"
     },
     "user_tz": 0
    },
    "id": "vFVQuMjUxBln",
    "outputId": "5ef90932-f3c8-4978-8ca6-71f605744c4b"
   },
   "outputs": [],
   "source": [
    "# #pull YOLOv5\n",
    "#!git clone https://github.com/ultralytics/yolov5\n",
    "#%cd $dir/yolov5\n",
    "#!git pull\n",
    "#!pip install -qr 'requirements.txt'  # install dependencies\n",
    "#%cd $dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1678136615529,
     "user": {
      "displayName": "Dinis Costa",
      "userId": "15980086246020437495"
     },
     "user_tz": 0
    },
    "id": "HcSKksgrxSqo"
   },
   "outputs": [],
   "source": [
    "#> /dev/null 2>&1\n",
    "def train(img=1280, epochs=50, data='data.yaml', name='new_train', project='train', weights=\"''\"):\n",
    "    !python {dir}/yolov5/train.py \\\n",
    "    --cache ram --batch -1 --epochs {epochs} --img {img} \\\n",
    "    --data {data} \\\n",
    "    --name {name} \\\n",
    "    --project {project}/train \\\n",
    "    --cfg yolov5s.yaml --weights {weights} \\\n",
    "    --device 0 > /dev/null 2>&1\n",
    "\n",
    "def detect(img=1280, source='imgs/', name='new_detect', project='detect', weights='best.pt'):\n",
    "    !python {dir}/yolov5/detect.py \\\n",
    "    --save-txt --save-conf \\\n",
    "    --source {dir}/{source} \\\n",
    "    --weights {weights} \\\n",
    "    --img {img} \\\n",
    "    --name {name} \\\n",
    "    --project {project}/detect \\\n",
    "    --device 0 > /dev/null 2>&1\n",
    "\n",
    "def test(img=1280, data='data.yaml', name='new_test', project='test', weights=\"''\"):\n",
    "    !python {dir}/yolov5/val.py \\\n",
    "    --data {dir}/{data} \\\n",
    "    --weights {weights} \\\n",
    "    --img {img} --task test \\\n",
    "    --name {name} \\\n",
    "    --project {project}/test \\\n",
    "    --device 0 --exist-ok > /dev/null 2>&1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Runs:   0%|                                              | 0/30 [00:00<?, ?it/s]\n",
      "Modes:   0%|                                              | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Splits:   0%|                                             | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Splits:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                              | 1/7 [08:13<49:20, 493.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "Splits:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 2/7 [17:52<45:17, 543.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "Splits:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 3/7 [29:07<40:15, 603.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "Splits:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ               | 4/7 [41:07<32:29, 649.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "Splits:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 5/7 [53:29<22:45, 682.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "Splits:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 6/7 [1:08:12<12:31, 751.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "Splits: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [1:24:37<00:00, 827.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "Modes:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 1/5 [1:32:17<6:09:10, 5537.66s/it]\u001b[A\n",
      "\n",
      "Splits:   0%|                                             | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Splits:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                              | 1/7 [09:10<55:03, 550.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "Splits:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 2/7 [19:46<50:04, 600.92s/it]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def run_all():\n",
    "    train_proportion = 0.6\n",
    "    val_proportion = 0.2\n",
    "    num_splits = 8\n",
    "    train_split_proportion = round(train_proportion / num_splits, 3)\n",
    "    val_split_proportion = 0#round(val_proportion / num_splits, 3)\n",
    "    num_runs = 30\n",
    "    split_type = True\n",
    "    epochs = 500\n",
    "\n",
    "    # Get initial train and validation splits\n",
    "    train_split, val_split = get_split(train_size=train_split_proportion, val_size=0.2)\n",
    "    experiment_name = '250eppochs'\n",
    "    project_name = f'train_output/{experiment_name}'\n",
    "    \n",
    "    # Loop through each run\n",
    "    for run in tqdm(range(num_runs), desc=\"Runs\", leave=True, position=0):\n",
    "        project = f'{project_name}_{run}'\n",
    "        \n",
    "        # Loop through each mode\n",
    "        for mode in tqdm([\"TL\", \"APPROACH\", \"RANDOM\", \"AL\", \"MA\"], desc=\"Modes\", leave=True, position=1):\n",
    "            name = f\"{mode}_split0\"\n",
    "            dataset = \"original\" if mode in [\"RANDOM\", \"AL\", \"TL\"] else \"improved\"\n",
    "            \n",
    "            # Split dataset\n",
    "            split_dataset(dataset=dataset, train_split=train_split, val_split=val_split)\n",
    "            \n",
    "            # Determine weights\n",
    "            weights = \"''\" if mode in [\"RANDOM\", \"AL\", \"MA\"] else f\"{dir}/bruno.pt\"\n",
    "            \n",
    "            # Train initial model\n",
    "            start = time.time()\n",
    "            train(project=project, name=name, epochs=epochs, weights=weights)\n",
    "            end = time.time() - start\n",
    "            \n",
    "            # Calculate number of images\n",
    "            images = math.floor(DATASET_SIZE * (train_split_proportion + val_split_proportion))\n",
    "            \n",
    "            # Log results\n",
    "            with open(f\"{project}.txt\", 'a') as file:\n",
    "                file.write(f\"{run}\\t{mode}\\t{images}\\t{end}\\t\")\n",
    "            \n",
    "            # Test initial model\n",
    "            test(name=project, weights=f\"{dir}/{project}/train/{name}/weights/best.pt\")\n",
    "            \n",
    "            # Loop through each split\n",
    "            for num in tqdm(range(1, num_splits), desc=\"Splits\", leave=False, position=2):\n",
    "                images += math.floor(DATASET_SIZE * (train_split_proportion + val_split_proportion))\n",
    "                \n",
    "                # Create new batch\n",
    "                new_batch(weights=f\"{dir}/{project}/train/{name}/weights/best.pt\", project=f\"{project}/batch\", name=name, mode=mode, split_random=split_type, train_size=train_split_proportion, val_size=val_split_proportion, dataset=dataset)\n",
    "                \n",
    "                name = f\"{mode}_split{num+1}\"\n",
    "                \n",
    "                # Train model on new batch\n",
    "                start = time.time()\n",
    "                train(project=project, name=name, epochs=epochs, weights=weights)\n",
    "                end = time.time() - start\n",
    "                \n",
    "                # Log results\n",
    "                with open(f\"{project}.txt\", 'a') as file:\n",
    "                    file.write(f\"{run}\\t{mode}\\t{images}\\t{end}\\t\")\n",
    "                \n",
    "                # Test model on new batch\n",
    "                test(name=project, weights=f\"{dir}/{project}/train/{name}/weights/best.pt\")\n",
    "\n",
    "\n",
    "run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ultralytics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m yolo\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Path to the YOLOv5 model weights\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/dinis/data-efficiency/RECPAD_250epochs__0/train/ALL_split16/weights/best.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'"
     ]
    }
   ],
   "source": [
    "from ultralytics import yolo\n",
    "\n",
    "\n",
    "# Path to the YOLOv5 model weights\n",
    "model_path = \"/home/dinis/data-efficiency/RECPAD_250epochs__0/train/ALL_split16/weights/best.pt\"\n",
    "\n",
    "# Initialize the YOLOv5 model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Path to the image for classification\n",
    "image_path = \"/home/dinis/data-efficiency/dataset/only_images/165.jpg\"\n",
    "\n",
    "# Perform inference on the image\n",
    "results = model.predict(image_path)\n",
    "\n",
    "# Display the output image with predictions\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (8.3.134)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from ultralytics) (2.2.5)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from ultralytics) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from ultralytics) (2.7.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from ultralytics) (0.22.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
      "Requirement already satisfied: filelock in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from triton==3.3.0->torch>=1.8.0->ultralytics) (80.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dinis/multimodal/.venv/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/home/dinis/data-efficiency/RECPAD_250epochs__0/train/ALL_split16/weights/best.pt'], source=/home/dinis/data-efficiency/VID_20221007_152743.mp4, data=yolov5/data/coco128.yaml, imgsz=[1280, 1280], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_format=0, save_csv=False, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 ðŸš€ v7.0-371-g6629839d Python-3.10.12 torch-2.7.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4090, 24215MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "video 1/1 (1/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 13 WFs, 17.3ms\n",
      "video 1/1 (2/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 12 WFs, 2.3ms\n",
      "video 1/1 (3/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 12 WFs, 2.3ms\n",
      "video 1/1 (4/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 12 WFs, 2.3ms\n",
      "video 1/1 (5/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 13 WFs, 2.3ms\n",
      "video 1/1 (6/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 12 WFs, 2.3ms\n",
      "video 1/1 (7/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 12 WFs, 2.3ms\n",
      "video 1/1 (8/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 12 WFs, 2.3ms\n",
      "video 1/1 (9/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (10/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 12 WFs, 2.3ms\n",
      "video 1/1 (11/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 13 WFs, 2.3ms\n",
      "video 1/1 (12/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 12 WFs, 2.3ms\n",
      "video 1/1 (13/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 12 WFs, 2.3ms\n",
      "video 1/1 (14/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (15/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (16/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (17/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (18/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (19/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (20/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (21/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (22/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (23/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 12 WFs, 2.3ms\n",
      "video 1/1 (24/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (25/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (26/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 12 WFs, 2.3ms\n",
      "video 1/1 (27/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (28/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (29/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (30/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (31/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 12 WFs, 2.3ms\n",
      "video 1/1 (32/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (33/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (34/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (35/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (36/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 12 WFs, 2.3ms\n",
      "video 1/1 (37/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (38/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (39/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 12 WFs, 2.3ms\n",
      "video 1/1 (40/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (41/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (42/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (43/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (44/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (45/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (46/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (47/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (48/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (49/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.4ms\n",
      "video 1/1 (50/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 11 WFs, 2.3ms\n",
      "video 1/1 (51/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 10 WFs, 2.3ms\n",
      "video 1/1 (52/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 9 WFs, 2.3ms\n",
      "video 1/1 (53/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 9 WFs, 2.3ms\n",
      "video 1/1 (54/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 9 WFs, 2.3ms\n",
      "video 1/1 (55/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 9 WFs, 2.3ms\n",
      "video 1/1 (56/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 9 WFs, 2.3ms\n",
      "video 1/1 (57/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 10 WFs, 2.3ms\n",
      "video 1/1 (58/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 9 WFs, 2.3ms\n",
      "video 1/1 (59/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 9 WFs, 2.3ms\n",
      "video 1/1 (60/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (61/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (62/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (63/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (64/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (65/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (66/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (67/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (68/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (69/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (70/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (71/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 9 WFs, 2.3ms\n",
      "video 1/1 (72/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (73/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (74/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (75/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (76/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (77/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (78/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 9 WFs, 2.3ms\n",
      "video 1/1 (79/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (80/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (81/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 8 WFs, 2.3ms\n",
      "video 1/1 (82/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 7 WFs, 2.3ms\n",
      "video 1/1 (83/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 7 WFs, 2.3ms\n",
      "video 1/1 (84/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 7 WFs, 2.3ms\n",
      "video 1/1 (85/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 7 WFs, 2.3ms\n",
      "video 1/1 (86/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 7 WFs, 2.3ms\n",
      "video 1/1 (87/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 7 WFs, 2.3ms\n",
      "video 1/1 (88/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 7 WFs, 2.3ms\n",
      "video 1/1 (89/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 6 WFs, 2.3ms\n",
      "video 1/1 (90/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 6 WFs, 2.3ms\n",
      "video 1/1 (91/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 6 WFs, 2.3ms\n",
      "video 1/1 (92/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 6 WFs, 2.3ms\n",
      "video 1/1 (93/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 6 WFs, 2.3ms\n",
      "video 1/1 (94/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 6 WFs, 2.3ms\n",
      "video 1/1 (95/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 7 WFs, 2.3ms\n",
      "video 1/1 (96/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 7 WFs, 2.3ms\n",
      "video 1/1 (97/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 6 WFs, 2.3ms\n",
      "video 1/1 (98/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (99/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (100/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 5 WFs, 2.3ms\n",
      "video 1/1 (101/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (102/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (103/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (104/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (105/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (106/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (107/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 6 WFs, 2.3ms\n",
      "video 1/1 (108/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (109/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (110/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (111/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (112/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (113/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (114/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (115/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (116/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (117/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (118/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (119/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (120/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (121/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (122/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (123/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (124/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 5 WFs, 2.3ms\n",
      "video 1/1 (125/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (126/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 6 WFs, 2.3ms\n",
      "video 1/1 (127/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (128/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (129/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (130/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (131/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (132/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (133/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (134/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (135/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (136/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (137/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (138/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (139/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (140/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (141/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (142/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (143/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (144/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (145/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (146/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (147/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (148/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (149/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (150/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 5 WFs, 2.3ms\n",
      "video 1/1 (151/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (152/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (153/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (154/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (155/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (156/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (157/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (158/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (159/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (160/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 5 WFs, 2.3ms\n",
      "video 1/1 (161/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 5 WFs, 2.3ms\n",
      "video 1/1 (162/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (163/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (164/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (165/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (166/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (167/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (168/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (169/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 5 WFs, 2.3ms\n",
      "video 1/1 (170/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (171/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (172/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (173/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (174/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (175/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (176/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (177/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (178/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (179/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (180/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (181/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (182/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (183/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (184/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (185/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (186/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (187/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (188/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (189/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (190/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (191/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (192/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (193/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (194/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (195/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (196/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (197/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (198/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (199/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (200/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (201/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (202/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (203/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (204/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (205/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (206/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (207/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (208/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (209/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (210/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (211/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (212/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (213/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (214/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (215/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (216/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (217/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (218/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (219/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (220/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (221/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (222/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (223/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (224/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (225/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (226/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (227/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (228/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (229/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (230/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (231/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (232/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (233/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (234/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (235/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (236/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (237/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (238/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (239/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (240/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (241/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (242/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (243/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (244/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (245/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (246/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (247/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (248/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (249/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (250/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (251/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (252/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (253/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (254/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (255/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (256/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (257/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (258/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (259/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (260/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (261/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (262/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (263/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (264/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (265/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (266/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (267/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (268/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (269/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (270/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (271/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (272/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (273/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (274/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (275/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (276/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (277/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (278/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (279/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (280/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (281/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (282/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (283/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (284/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (285/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (286/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (287/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (288/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (289/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (290/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (291/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (292/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (293/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (294/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (295/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (296/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (297/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (298/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (299/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (300/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (301/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (302/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (303/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (304/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (305/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (306/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (307/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (308/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (309/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (310/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (311/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (312/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (313/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (314/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (315/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (316/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (317/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (318/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (319/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (320/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (321/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (322/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (323/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (324/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (325/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (326/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (327/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (328/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (329/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (330/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (331/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (332/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (333/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (334/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (335/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (336/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (337/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (338/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (339/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (340/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (341/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (342/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (343/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 (no detections), 2.3ms\n",
      "video 1/1 (344/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (345/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (346/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (347/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (348/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (349/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (350/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (351/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 (no detections), 2.3ms\n",
      "video 1/1 (352/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (353/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (354/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (355/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (356/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (357/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (358/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (359/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 (no detections), 2.3ms\n",
      "video 1/1 (360/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (361/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (362/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (363/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (364/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (365/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (366/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 1 WF, 2.3ms\n",
      "video 1/1 (367/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (368/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (369/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (370/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (371/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (372/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (373/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (374/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (375/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (376/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (377/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (378/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (379/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (380/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 4 WFs, 2.3ms\n",
      "video 1/1 (381/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (382/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (383/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 3 WFs, 2.3ms\n",
      "video 1/1 (384/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (385/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (386/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 2 WFs, 2.3ms\n",
      "video 1/1 (387/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 (no detections), 2.3ms\n",
      "video 1/1 (388/388) /home/dinis/data-efficiency/VID_20221007_152743.mp4: 736x1280 (no detections), 2.3ms\n",
      "Speed: 0.4ms pre-process, 2.3ms inference, 0.9ms NMS per image at shape (1, 3, 1280, 1280)\n",
      "Results saved to \u001b[1myolov5/runs/detect/exp2\u001b[0m\n",
      "383 labels saved to yolov5/runs/detect/exp2/labels\n"
     ]
    }
   ],
   "source": [
    "#!pip install ultralytics\n",
    "!python yolov5/detect.py \\\n",
    "  --weights /home/dinis/data-efficiency/RECPAD_250epochs__0/train/ALL_split16/weights/best.pt \\\n",
    "  --source /home/dinis/data-efficiency/VID_20221007_152743.mp4 \\\n",
    "  --img 1280 \\\n",
    "  --conf 0.25 \\\n",
    "  --save-txt \\\n",
    "  --save-conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.159 ðŸš€ Python-3.11.5 torch-2.7.1 CPU (Apple M3 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=2, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=128, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=new_train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=train/new_train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  2    180864  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n",
      " 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 21        [14, 17, 20]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv12n summary: 272 layers, 2,568,243 parameters, 2,568,227 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 640/691 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1971.0Â±363.2 MB/s, size: 758.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/dataset/run/train... 120 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:00<00:00, 4029.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/dataset/run/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2017.2Â±333.9 MB/s, size: 879.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/dataset/run/val... 40 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 4358.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/dataset/run/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to train/new_train3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\n",
      "Image sizes 128 train, 128 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mtrain/new_train3\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G    0.03777     0.6068   0.007247          2        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:13<00:00,  4.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       3061          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G    0.04973     0.5703   0.009716         35        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:14<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       3061          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G     0.1079     0.6052    0.02101          3        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:13<00:00,  4.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       3061          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50         0G     0.2193     0.6386     0.0354          9        128:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 42/60 [00:09<00:04,  4.35it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m train,val = get_split(train_size=\u001b[32m0.6\u001b[39m, val_size=\u001b[32m0.2\u001b[39m, test_size=\u001b[32m0.2\u001b[39m)\n\u001b[32m      5\u001b[39m split_dataset(train_split=train, val_split=val, test_split=[], dataset=\u001b[33m\"\u001b[39m\u001b[33mimproved\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mtrain_yolov12\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/utils/object_detection.py:47\u001b[39m, in \u001b[36mtrain_yolov12\u001b[39m\u001b[34m(img, epochs, data, name, project, weights)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_yolov12\u001b[39m(img=\u001b[32m128\u001b[39m, epochs=\u001b[32m50\u001b[39m, data=\u001b[33m'\u001b[39m\u001b[33mdataset/data.yaml\u001b[39m\u001b[33m'\u001b[39m, name=\u001b[33m'\u001b[39m\u001b[33mnew_train\u001b[39m\u001b[33m'\u001b[39m, project=\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m, weights=\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     46\u001b[39m     model = YOLO(\u001b[33m\"\u001b[39m\u001b[33myolo12n.pt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights == \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m weights)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.11/site-packages/ultralytics/engine/model.py:797\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    794\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m    796\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.hub_session = \u001b[38;5;28mself\u001b[39m.session  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m797\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.11/site-packages/ultralytics/engine/trainer.py:227\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    224\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.11/site-packages/ultralytics/engine/trainer.py:388\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self, world_size)\u001b[39m\n\u001b[32m    386\u001b[39m     pbar = TQDM(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_loader), total=nb)\n\u001b[32m    387\u001b[39m \u001b[38;5;28mself\u001b[39m.tloss = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mon_train_batch_start\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Warmup\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.11/site-packages/ultralytics/data/build.py:67\u001b[39m, in \u001b[36mInfiniteDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create an iterator that yields indefinitely from the underlying iterator.\"\"\"\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.11/site-packages/ultralytics/data/base.py:379\u001b[39m, in \u001b[36mBaseDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    378\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return transformed label information for given index.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_image_and_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.11/site-packages/ultralytics/data/base.py:393\u001b[39m, in \u001b[36mBaseDataset.get_image_and_label\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    391\u001b[39m label = deepcopy(\u001b[38;5;28mself\u001b[39m.labels[index])  \u001b[38;5;66;03m# requires deepcopy() https://github.com/ultralytics/ultralytics/pull/1948\u001b[39;00m\n\u001b[32m    392\u001b[39m label.pop(\u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# shape is for rect, remove it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m label[\u001b[33m\"\u001b[39m\u001b[33mimg\u001b[39m\u001b[33m\"\u001b[39m], label[\u001b[33m\"\u001b[39m\u001b[33mori_shape\u001b[39m\u001b[33m\"\u001b[39m], label[\u001b[33m\"\u001b[39m\u001b[33mresized_shape\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    394\u001b[39m label[\u001b[33m\"\u001b[39m\u001b[33mratio_pad\u001b[39m\u001b[33m\"\u001b[39m] = (\n\u001b[32m    395\u001b[39m     label[\u001b[33m\"\u001b[39m\u001b[33mresized_shape\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m] / label[\u001b[33m\"\u001b[39m\u001b[33mori_shape\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    396\u001b[39m     label[\u001b[33m\"\u001b[39m\u001b[33mresized_shape\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m1\u001b[39m] / label[\u001b[33m\"\u001b[39m\u001b[33mori_shape\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m1\u001b[39m],\n\u001b[32m    397\u001b[39m )  \u001b[38;5;66;03m# for evaluation\u001b[39;00m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rect:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.11/site-packages/ultralytics/data/base.py:236\u001b[39m, in \u001b[36mBaseDataset.load_image\u001b[39m\u001b[34m(self, i, rect_mode)\u001b[39m\n\u001b[32m    234\u001b[39m         im = imread(f, flags=\u001b[38;5;28mself\u001b[39m.cv2_flag)  \u001b[38;5;66;03m# BGR\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# read image\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     im = \u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv2_flag\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# BGR\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m im \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mImage Not Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.11/site-packages/ultralytics/utils/patches.py:41\u001b[39m, in \u001b[36mimread\u001b[39m\u001b[34m(filename, flags)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     im = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m im[..., \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;28;01mif\u001b[39;00m im.ndim == \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m im\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from utils import train_yolov12\n",
    "from utils import get_split, split_dataset\n",
    "\n",
    "train,val = get_split(train_size=0.6, val_size=0.2, test_size=0.2)\n",
    "split_dataset(train_split=train, val_split=val, test_split=[], dataset=\"improved\")\n",
    "\n",
    "train_yolov12()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "provenance": [
    {
     "file_id": "1yMfa2LVe_rcHl-nijkMI7foC2RPtpcjM",
     "timestamp": 1671628187174
    }
   ]
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
