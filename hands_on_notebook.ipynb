{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e01772",
   "metadata": {},
   "source": [
    "# üìò IbPRIA 2025 - Data-Efficient Strategies for Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c69f66",
   "metadata": {},
   "source": [
    "> üìå **Note**: You can run this notebook on:\n",
    ">\n",
    "> - üíª Your local machine (Python ‚â• 3.8, see `requirements.txt`)\n",
    "> - üåê [Google Colab](https://colab.research.google.com/github/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/blob/main/hands_on_notebook.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec05742",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Preparation to Run This Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16179b25",
   "metadata": {},
   "source": [
    "To ensure faster training and better performance, it is recommended to use a **GPU** when running this notebook.\n",
    "\n",
    "If you're using **Google Colab**, make sure the runtime is configured to use a **GPU** or **TPU**.\n",
    "\n",
    "> üìå You can change the runtime by going to:  \n",
    "> `Runtime` ‚Üí `Change runtime type` ‚Üí Select **GPU** or **TPU**\n",
    "\n",
    "‚¨áÔ∏è See the image below for guidance.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** You can also run this notebook **locally** using your own machine with **CPU only**.  \n",
    "Training may be slower, but all code will still work correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a228b69",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/colab_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b17048",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/colab_2_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861d6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"COLAB_RELEASE_TAG\" in os.environ:\n",
    "    print(\"‚úÖ Running on Google Colab\")\n",
    "    # Clone the repository if running in Google Colab\n",
    "    !git clone https://github.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection.git\n",
    "    # Change working directory\n",
    "    os.chdir(\"IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection\")\n",
    "\n",
    "%pip install -r requirements.txt # Install required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a6e2c1",
   "metadata": {},
   "source": [
    "## ‚úèÔ∏è Annotation Guidelines for Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35bf29d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In object detection tasks, each image must be labeled with **bounding boxes** that enclose every object the model is expected to detect. For each bounding box, a corresponding **class label** must be assigned.\n",
    "\n",
    "There are several tools available for this annotation process:\n",
    "\n",
    "- If you're working with a **small dataset** and need a lightweight solution, we recommend [labelImg](https://pypi.org/project/labelImg/).\n",
    "- For **larger projects** with multiple annotators, we suggest using a more robust platform such as [Label Studio](https://labelstud.io/), which provide better support for collaboration.\n",
    "\n",
    "### Bounding Box Best Practices\n",
    "\n",
    "A bounding box is defined by its **center coordinates**, **width**, and **height**. For accurate annotations:\n",
    "\n",
    "- The **center of the bounding box** should align with the center of the corresponding object.\n",
    "- The edges of the bounding box should **not exceed the boundaries** of the object.\n",
    "- Boxes should be **tight** but not overly precise ‚Äî enough to capture the object clearly without including background noise.\n",
    "\n",
    "> Ensuring consistent and accurate annotation is crucial, as it directly impacts the performance and reliability of the trained object detection model.\n",
    "\n",
    "### Running LabelImg Locally\n",
    "\n",
    "If you're running this notebook or working locally (not on Colab), you can install and launch **LabelImg** using the commands below:\n",
    "\n",
    "```bash\n",
    "pip install labelImg\n",
    "```\n",
    "**Important:** LabelImg works best with Python 3.9 or lower. Newer versions may cause compatibility issues. We recommend using a virtual environment with Python 3.9 if needed.\n",
    "\n",
    "To lauch the tool:\n",
    "```bash\n",
    "labelImg\n",
    "```\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/labelimg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f7c5bb",
   "metadata": {},
   "source": [
    "## üìÇ Dataset Format for YOLO Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1825ff24",
   "metadata": {},
   "source": [
    "\n",
    "To train a YOLO model, your dataset must follow a specific structure and include a `.yaml` configuration file that defines where your images and annotations are located, along with the list of classes.\n",
    "\n",
    "---\n",
    "\n",
    "### Folder Structure\n",
    "\n",
    "Each image should have a corresponding `.txt` annotation file with the same name (e.g., `image1.jpg` ‚Üî `image1.txt`), and these should be placed in the appropriate subfolders.\n",
    "\n",
    "```text\n",
    "dataset/\n",
    "‚îú‚îÄ‚îÄ train/\n",
    "‚îú‚îÄ‚îÄ val/\n",
    "‚îú‚îÄ‚îÄ test/\n",
    "‚îî‚îÄ‚îÄ data.yaml\n",
    "```\n",
    "\n",
    "> **Note:** YOLO expects labels in `.txt` format where each line corresponds to one bounding box, with the format:\n",
    ">\n",
    "> ```\n",
    "> <class_id> <x_center> <y_center> <width> <height>\n",
    "> ```\n",
    "> All values must be normalized (from 0 to 1) relative to image size.\n",
    "\n",
    "---\n",
    "\n",
    "### `data.yaml` Example\n",
    "\n",
    "```yaml\n",
    "train: dataset/train/images\n",
    "val: dataset/val/images\n",
    "test: dataset/test/images\n",
    "\n",
    "nc: 1  # number of classes\n",
    "names: ['WF'] #name of the class that MUST match the <class_id> in the annotation file\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b2cbe9",
   "metadata": {},
   "source": [
    "## üëÅÔ∏è Object Detection with YOLOv11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdd2334",
   "metadata": {},
   "source": [
    "\n",
    "Once your dataset is prepared and organized correctly, you can begin training your YOLOv11 model. In this example, we‚Äôll use the **nano version** of YOLOv11 (`yolov11n.pt`) and train on a custom dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69141f9a",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1: Dataset Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32724b41",
   "metadata": {},
   "source": [
    "We use a utility function to split the dataset into **training** and **validation** sets, assuming a separate **test set** already exists.\n",
    "\n",
    "This example splits a dataset of 200 images into:\n",
    "- **60% for training**\n",
    "- **20% for validation**\n",
    "- The remaining **20% are reserved as the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e9ad0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and validation splits saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from utils import get_split, split_dataset\n",
    "\n",
    "# Get train/val split from dataset (test already fixed)\n",
    "train, val = get_split(train_size=0.6, val_size=0.2, dataset_size=200)\n",
    "\n",
    "# Save to dataset/run/train and dataset/run/val\n",
    "split_dataset(train_split=train, val_split=val)\n",
    "print(\"Train and validation splits saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19989df4",
   "metadata": {},
   "source": [
    "### Step 2: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8507b8",
   "metadata": {},
   "source": [
    "After the dataset splitting process, it is important to define the training parameters.\n",
    "\n",
    "Some important parameters to define are: **image size**, number of **epochs**, how to initialize the model **weights**, and the **batch size**.\n",
    "\n",
    "Let us clarify each of them:\n",
    "\n",
    "**Image size** refers to the resolution to which every input image is resized before being fed into the yolov11 model. This fixed-size input is necessary because the model architecture (fully convolutional with final dense layers) expects inputs of the same size.\n",
    "\n",
    "An **epoch** is one complete pass through the entire training dataset by the learning algorithm.\n",
    "\n",
    "Pre-trained **weights** are obtained by training a model on a large dataset before applying it to a specific task. This approach leverages **transfer learning**, allowing the model to take advantage of already learned general features such as edges, textures, or shapes. We will further explore **transfer learning** and its advantages.\n",
    "\n",
    "Finally, **batch size** is the number of training samples processed before the model updates its weights.\n",
    "\n",
    "For each batch:\n",
    "- The model makes predictions.\n",
    "- The loss is computed.\n",
    "- The optimizer adjusts weights using gradients from that batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a8607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.160 üöÄ Python-3.9.6 torch-2.7.1 CPU (Apple M3 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=5, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=608, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov11n_custom, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=example_simple_detector, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=example_simple_detector/yolov11n_custom, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1604.7¬±674.0 MB/s, size: 951.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/dataset/run/train... 120 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:00<00:00, 3891.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/dataset/run/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 7401.7¬±2582.0 MB/s, size: 647.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/dataset/run/val... 40 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 3820.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/dataset/run/val.cache\n",
      "Plotting labels to example_simple_detector/yolov11n_custom/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 608 train, 608 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mexample_simple_detector/yolov11n_custom\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         0G      2.864       3.78      1.008        336        608: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:32<00:00,  1.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       2004    0.00458     0.0274    0.00237    0.00083\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/5         0G      2.504      2.338      0.899        286        608: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:32<00:00,  1.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       2004     0.0153     0.0918    0.00913      0.003\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/5         0G      2.583      2.008     0.8911        571        608: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:32<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       2004      0.269      0.349      0.248      0.086\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        4/5         0G      2.543      1.871     0.8888        207        608: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:31<00:00,  1.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       2004      0.617      0.309       0.34      0.125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        5/5         0G      2.445      1.772     0.8756         77        608: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:32<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       2004        0.6      0.358      0.368      0.157\n",
      "\n",
      "5 epochs completed in 0.050 hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from example_simple_detector/yolov11n_custom/weights/last.pt, 5.5MB\n",
      "Optimizer stripped from example_simple_detector/yolov11n_custom/weights/best.pt, 5.5MB\n",
      "\n",
      "Validating example_simple_detector/yolov11n_custom/weights/best.pt...\n",
      "Ultralytics 8.3.160 üöÄ Python-3.9.6 torch-2.7.1 CPU (Apple M3 Pro)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       2004      0.599      0.358      0.368      0.157\n",
      "Speed: 0.5ms preprocess, 40.9ms inference, 0.0ms loss, 10.1ms postprocess per image\n",
      "Results saved to \u001b[1mexample_simple_detector/yolov11n_custom\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x3031f7850>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.96341,     0.96341,     0.96341,     0.96341,     0.95402,     0.95402,     0.94444,     0.93651,     0.93651,     0.93651,\n",
       "            0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,\n",
       "            0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93651,     0.93264,     0.93035,     0.93035,\n",
       "            0.93035,     0.93035,     0.92344,     0.92344,     0.92344,     0.92105,     0.92105,     0.92105,     0.92105,     0.92105,     0.92105,     0.92105,     0.92105,     0.91139,     0.91139,     0.91139,     0.90417,     0.90283,     0.90283,     0.90283,     0.89963,     0.89963,     0.89963,\n",
       "            0.89963,     0.89963,     0.89963,     0.89963,     0.89963,     0.89963,      0.8917,      0.8917,      0.8917,     0.88339,     0.88112,     0.87889,     0.86577,     0.86577,     0.86333,     0.86184,     0.85668,     0.85397,     0.85397,     0.85397,     0.84404,     0.84404,     0.84404,\n",
       "             0.8429,      0.8429,     0.83815,     0.83815,     0.83815,     0.83815,     0.83815,     0.83761,     0.83761,     0.83417,     0.83417,     0.83417,     0.83417,     0.83417,     0.83417,     0.83417,     0.83417,     0.83417,     0.83417,     0.83417,     0.83417,     0.83417,     0.83417,\n",
       "            0.83417,     0.83417,     0.83417,     0.83417,     0.83417,     0.83416,     0.83416,     0.83409,     0.83409,     0.83409,     0.83409,     0.83409,     0.83409,     0.83409,     0.83409,     0.83409,     0.83409,     0.83409,     0.83409,     0.83409,     0.83409,     0.83409,     0.82921,\n",
       "            0.82655,     0.82655,     0.82655,     0.82655,     0.82655,     0.82655,     0.82655,     0.82655,     0.82655,     0.82563,     0.82563,     0.82563,     0.82463,     0.82365,     0.82062,     0.81967,     0.81542,     0.81532,     0.81532,     0.81532,     0.81532,     0.81532,     0.81532,\n",
       "            0.81445,     0.81274,     0.81274,      0.8119,     0.81071,     0.80989,     0.80863,     0.80863,     0.80784,     0.80519,     0.80212,     0.80212,     0.80212,     0.80212,     0.80212,     0.80212,     0.80212,     0.80212,     0.80212,     0.80212,      0.7986,     0.79447,     0.79447,\n",
       "            0.79316,     0.79316,     0.78824,     0.78824,     0.78641,     0.78641,     0.78641,     0.78641,     0.78641,     0.78641,     0.78641,     0.78641,     0.78641,     0.78617,     0.78309,     0.78254,     0.78076,     0.77987,     0.77812,      0.7776,     0.77542,     0.77542,     0.77542,\n",
       "            0.77542,     0.77542,     0.77049,     0.77049,     0.77049,     0.77037,     0.77037,     0.77035,     0.77035,     0.77035,     0.77035,     0.77035,     0.76724,     0.76724,     0.76714,     0.76562,     0.76379,     0.75698,     0.75661,     0.75414,     0.75205,     0.75034,     0.74629,\n",
       "            0.74362,     0.73936,     0.73844,      0.7356,      0.7356,     0.73316,     0.73316,     0.73136,     0.72624,     0.72624,     0.72601,     0.72453,     0.72285,     0.72229,     0.72208,     0.72044,     0.72005,     0.72005,     0.71928,     0.71928,     0.71928,     0.71928,     0.71789,\n",
       "             0.7104,     0.70574,     0.70478,      0.7022,     0.70127,     0.70034,     0.69625,     0.69605,     0.69605,     0.69516,     0.68966,     0.68954,     0.68954,     0.68954,     0.68954,     0.68954,     0.68954,     0.68947,     0.68906,     0.68824,      0.6867,     0.68225,     0.67647,\n",
       "            0.67326,      0.6715,     0.67044,     0.66872,     0.66871,     0.66633,     0.66566,     0.66533,     0.66533,     0.66533,     0.66175,     0.66175,     0.66175,     0.66175,     0.65728,     0.65728,     0.64734,     0.64734,     0.63628,     0.63611,     0.63611,     0.63303,     0.63139,\n",
       "            0.63091,      0.6301,     0.62747,     0.62747,     0.62645,     0.61829,     0.61518,     0.61478,     0.60769,     0.60769,     0.60629,      0.6032,      0.6005,     0.59884,     0.59884,     0.59868,     0.59868,     0.59737,     0.59462,      0.5919,     0.58828,     0.58519,     0.57713,\n",
       "            0.57644,     0.56956,     0.56459,     0.56269,     0.55399,     0.55399,     0.54638,     0.54638,     0.54631,     0.54618,     0.54363,     0.54164,     0.54152,     0.53976,     0.53976,     0.53664,     0.53389,     0.53274,     0.52189,     0.51899,     0.51899,     0.51513,     0.51513,\n",
       "            0.50547,     0.50416,     0.49843,     0.49843,     0.49843,     0.49657,     0.49657,     0.48988,     0.48282,     0.47769,      0.4744,     0.47387,     0.47145,     0.46852,     0.45958,     0.45253,     0.43388,     0.42708,     0.42701,     0.42445,     0.42402,      0.4189,      0.4189,\n",
       "             0.4178,     0.41754,     0.41563,     0.41313,     0.41107,     0.40925,     0.40793,     0.40684,     0.40604,     0.40525,     0.39897,     0.39795,     0.39419,     0.39097,      0.3828,     0.38013,     0.37603,     0.37349,      0.3729,       0.372,     0.36829,     0.36712,     0.36688,\n",
       "             0.3636,     0.36158,     0.35493,     0.35318,     0.35119,     0.34798,     0.34565,     0.33813,     0.33736,     0.32346,     0.31081,      0.3084,     0.30803,     0.29275,     0.29212,      0.2837,      0.2779,     0.27366,     0.26948,     0.25972,      0.2565,     0.25457,     0.25261,\n",
       "            0.24587,     0.23555,     0.23262,     0.22467,     0.22337,     0.21779,      0.2142,     0.21276,     0.20922,     0.20102,     0.19815,     0.19381,     0.19054,     0.18882,     0.18488,     0.17496,     0.17173,     0.16757,     0.16205,     0.16054,      0.1586,     0.15683,     0.15178,\n",
       "            0.15065,     0.14797,     0.14087,     0.10866,     0.09657,    0.084843,    0.081429,     0.08127,     0.08111,     0.08095,    0.080791,    0.080631,    0.080471,    0.080312,    0.080152,    0.079992,    0.079833,    0.079673,    0.079513,    0.079354,    0.079194,    0.079034,    0.078875,\n",
       "           0.078715,    0.078555,    0.078396,    0.078236,    0.078076,    0.077917,    0.077757,    0.077597,    0.077438,    0.077278,    0.077118,    0.076959,    0.076799,    0.076639,     0.07648,     0.07632,     0.07616,    0.076001,    0.075841,    0.075681,    0.075522,    0.075362,    0.075202,\n",
       "           0.075043,    0.074883,    0.074723,    0.074564,    0.074404,    0.074244,    0.074085,    0.073925,    0.073765,    0.073606,    0.073446,    0.073286,    0.073127,    0.072967,    0.072807,    0.072648,    0.072488,    0.072328,    0.072169,    0.072009,    0.071849,     0.07169,     0.07153,\n",
       "            0.07137,    0.071211,    0.071051,    0.070891,    0.070732,    0.070572,    0.070412,    0.070253,    0.070093,    0.069933,    0.069774,    0.069614,    0.069454,    0.069295,    0.069135,    0.068975,    0.068816,    0.068656,    0.068496,    0.068337,    0.068177,    0.068017,    0.067858,\n",
       "           0.067698,    0.067538,    0.067379,    0.067219,    0.067059,      0.0669,     0.06674,     0.06658,    0.066421,    0.066261,    0.066101,    0.065942,    0.065782,    0.065622,    0.065463,    0.065303,    0.065143,    0.064984,    0.064824,    0.064664,    0.064505,    0.064345,    0.064185,\n",
       "           0.064026,    0.063866,    0.063706,    0.063547,    0.063387,    0.063227,    0.063068,    0.062908,    0.062748,    0.062589,    0.062429,    0.062269,     0.06211,     0.06195,     0.06179,    0.061631,    0.061471,    0.061311,    0.061152,    0.060992,    0.060832,    0.060673,    0.060513,\n",
       "           0.060353,    0.060194,    0.060034,    0.059874,    0.059715,    0.059555,    0.059395,    0.059236,    0.059076,    0.058916,    0.058757,    0.058597,    0.058437,    0.058278,    0.058118,    0.057958,    0.057799,    0.057639,    0.057479,     0.05732,     0.05716,       0.057,    0.056841,\n",
       "           0.056681,    0.056521,    0.056362,    0.056202,    0.056042,    0.055883,    0.055723,    0.055563,    0.055404,    0.055244,    0.055084,    0.054925,    0.054765,    0.054605,    0.054446,    0.054286,    0.054126,    0.053967,    0.053807,    0.053647,    0.053488,    0.053328,    0.053168,\n",
       "           0.053009,    0.052849,    0.052689,     0.05253,     0.05237,     0.05221,    0.052051,    0.051891,    0.051731,    0.051572,    0.051412,    0.051252,    0.051093,    0.050933,    0.050773,    0.050614,    0.050454,    0.050294,    0.050135,    0.049975,    0.049815,    0.049656,    0.049496,\n",
       "           0.049336,    0.049177,    0.049017,    0.048857,    0.048698,    0.048538,    0.048379,    0.048219,    0.048059,      0.0479,     0.04774,     0.04758,    0.047421,    0.047261,    0.047101,    0.046942,    0.046782,    0.046622,    0.046463,    0.046303,    0.046143,    0.045984,    0.045824,\n",
       "           0.045664,    0.045505,    0.045345,    0.045185,    0.045026,    0.044866,    0.044706,    0.044547,    0.044387,    0.044227,    0.044068,    0.043908,    0.043748,    0.043589,    0.043429,    0.043269,     0.04311,     0.04295,     0.04279,    0.042631,    0.042471,    0.042311,    0.042152,\n",
       "           0.041992,    0.041832,    0.041673,    0.041513,    0.041353,    0.041194,    0.041034,    0.040874,    0.040715,    0.040555,    0.040395,    0.040236,    0.040076,    0.039916,    0.039757,    0.039597,    0.039437,    0.039278,    0.039118,    0.038958,    0.038799,    0.038639,    0.038479,\n",
       "            0.03832,     0.03816,       0.038,    0.037841,    0.037681,    0.037521,    0.037362,    0.037202,    0.037042,    0.036883,    0.036723,    0.036563,    0.036404,    0.036244,    0.036084,    0.035925,    0.035765,    0.035605,    0.035446,    0.035286,    0.035126,    0.034967,    0.034807,\n",
       "           0.034647,    0.034488,    0.034328,    0.034168,    0.034009,    0.033849,    0.033689,     0.03353,     0.03337,     0.03321,    0.033051,    0.032891,    0.032731,    0.032572,    0.032412,    0.032252,    0.032093,    0.031933,    0.031773,    0.031614,    0.031454,    0.031294,    0.031135,\n",
       "           0.030975,    0.030815,    0.030656,    0.030496,    0.030336,    0.030177,    0.030017,    0.029857,    0.029698,    0.029538,    0.029378,    0.029219,    0.029059,    0.028899,     0.02874,     0.02858,     0.02842,    0.028261,    0.028101,    0.027941,    0.027782,    0.027622,    0.027462,\n",
       "           0.027303,    0.027143,    0.026983,    0.026824,    0.026664,    0.026504,    0.026345,    0.026185,    0.026025,    0.025866,    0.025706,    0.025546,    0.025387,    0.025227,    0.025067,    0.024908,    0.024748,    0.024588,    0.024429,    0.024269,    0.024109,     0.02395,     0.02379,\n",
       "            0.02363,    0.023471,    0.023311,    0.023151,    0.022992,    0.022832,    0.022672,    0.022513,    0.022353,    0.022193,    0.022034,    0.021874,    0.021714,    0.021555,    0.021395,    0.021235,    0.021076,    0.020916,    0.020756,    0.020597,    0.020437,    0.020277,    0.020118,\n",
       "           0.019958,    0.019798,    0.019639,    0.019479,    0.019319,     0.01916,       0.019,     0.01884,    0.018681,    0.018521,    0.018361,    0.018202,    0.018042,    0.017882,    0.017723,    0.017563,    0.017403,    0.017244,    0.017084,    0.016924,    0.016765,    0.016605,    0.016445,\n",
       "           0.016286,    0.016126,    0.015967,    0.015807,    0.015647,    0.015488,    0.015328,    0.015168,    0.015009,    0.014849,    0.014689,     0.01453,     0.01437,     0.01421,    0.014051,    0.013891,    0.013731,    0.013572,    0.013412,    0.013252,    0.013093,    0.012933,    0.012773,\n",
       "           0.012614,    0.012454,    0.012294,    0.012135,    0.011975,    0.011815,    0.011656,    0.011496,    0.011336,    0.011177,    0.011017,    0.010857,    0.010698,    0.010538,    0.010378,    0.010219,    0.010059,   0.0098992,   0.0097396,   0.0095799,   0.0094202,   0.0092606,   0.0091009,\n",
       "          0.0089412,   0.0087816,   0.0086219,   0.0084622,   0.0083026,   0.0081429,   0.0079833,   0.0078236,   0.0076639,   0.0075043,   0.0073446,   0.0071849,   0.0070253,   0.0068656,   0.0067059,   0.0065463,   0.0063866,   0.0062269,   0.0060673,   0.0059076,   0.0057479,   0.0055883,   0.0054286,\n",
       "          0.0052689,   0.0051093,   0.0049496,     0.00479,   0.0046303,   0.0044706,    0.004311,   0.0041513,   0.0039916,    0.003832,   0.0036723,   0.0035126,    0.003353,   0.0031933,   0.0030336,    0.002874,   0.0027143,   0.0025546,    0.002395,   0.0022353,   0.0020756,    0.001916,   0.0017563,\n",
       "          0.0015967,    0.001437,   0.0012773,   0.0011177,  0.00095799,  0.00079833,  0.00063866,    0.000479,  0.00031933,  0.00015967,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.13982,     0.13982,     0.13982,     0.13982,     0.13982,     0.13982,     0.13982,     0.13982,     0.14046,     0.14324,     0.15291,     0.18267,     0.21991,      0.2356,     0.24585,     0.25567,     0.26544,     0.27292,      0.2806,     0.28854,     0.29483,     0.30146,     0.30824,\n",
       "            0.31392,     0.32053,     0.32576,     0.33013,     0.33568,     0.34088,     0.34535,     0.34854,     0.35406,     0.35711,     0.36052,     0.36416,     0.36669,     0.37037,     0.37496,     0.37827,     0.38206,     0.38469,     0.38794,     0.38979,     0.39235,     0.39585,     0.39751,\n",
       "            0.39837,     0.40041,     0.40131,      0.4037,     0.40603,      0.4085,     0.41041,      0.4117,     0.41394,     0.41396,     0.41453,     0.41598,      0.4161,     0.41743,     0.41779,     0.41922,     0.42073,     0.42344,     0.42561,     0.42774,      0.4285,     0.43003,     0.43135,\n",
       "            0.43311,     0.43424,     0.43487,     0.43479,     0.43423,     0.43579,     0.43708,     0.43874,     0.44021,      0.4415,     0.43882,     0.44049,     0.44136,     0.44234,     0.44369,     0.44313,     0.44331,     0.44399,     0.44575,     0.44682,     0.44716,     0.44736,     0.44733,\n",
       "            0.44677,     0.44641,     0.44577,     0.44597,     0.44437,     0.44578,     0.44581,     0.44705,     0.44764,     0.44718,     0.44815,     0.44844,     0.44966,     0.44896,     0.44975,     0.45042,     0.45035,     0.45085,     0.45098,     0.45132,     0.45103,     0.44989,     0.44957,\n",
       "            0.44865,     0.44813,     0.44858,     0.44845,     0.44806,     0.44671,     0.44689,     0.44779,     0.44831,     0.44769,     0.44778,      0.4483,     0.44842,     0.44711,     0.44705,     0.44713,     0.44571,      0.4453,      0.4434,     0.44442,     0.44444,     0.44517,     0.44475,\n",
       "            0.44459,     0.44569,     0.44582,     0.44582,     0.44509,     0.44505,     0.44217,     0.44212,     0.44134,     0.44006,     0.43923,     0.43861,     0.43845,     0.43762,     0.43722,     0.43627,     0.43546,     0.43494,      0.4355,     0.43558,     0.43566,     0.43538,     0.43561,\n",
       "            0.43572,     0.43503,     0.43449,     0.43348,     0.43274,     0.42883,     0.42702,     0.42673,     0.42626,     0.42669,     0.42649,     0.42628,     0.42623,     0.42607,     0.42458,     0.42387,     0.42376,     0.42414,     0.42384,     0.42346,     0.42214,      0.4217,     0.42133,\n",
       "            0.42128,     0.42089,     0.42091,     0.42086,      0.4212,     0.42157,     0.42068,      0.4197,     0.41764,     0.41728,     0.41741,      0.4167,     0.41534,     0.41403,     0.41348,     0.41314,     0.41228,     0.41123,      0.4109,     0.40898,     0.40839,     0.40846,     0.40779,\n",
       "            0.40609,     0.40586,     0.40588,     0.40498,     0.40455,     0.40482,     0.40391,     0.40281,     0.40249,     0.40262,     0.40202,     0.40133,      0.4015,     0.40063,     0.40021,     0.40014,     0.39901,     0.39833,     0.39756,     0.39793,     0.39838,     0.39793,     0.39772,\n",
       "            0.39716,     0.39666,     0.39545,      0.3947,       0.394,      0.3936,     0.39227,     0.39153,     0.38993,     0.38968,     0.38875,     0.38796,      0.3864,     0.38633,     0.38556,     0.38307,     0.38373,     0.38231,     0.38158,     0.37967,     0.37813,     0.37771,     0.37601,\n",
       "            0.37568,     0.37514,     0.37409,     0.37422,     0.37419,     0.37315,     0.37179,     0.37062,     0.36944,     0.36911,     0.36813,      0.3676,     0.36772,     0.36466,     0.36474,     0.36435,     0.36389,     0.36335,     0.36181,     0.36081,     0.35999,     0.35857,     0.35751,\n",
       "            0.35666,     0.35492,      0.3537,      0.3537,     0.35379,     0.35405,     0.35413,     0.35395,     0.35362,     0.35188,     0.35129,     0.34941,     0.34901,     0.34809,     0.34781,     0.34754,     0.34724,     0.34572,     0.34529,       0.345,     0.34454,     0.34419,     0.34164,\n",
       "            0.34111,     0.34085,     0.34023,     0.33989,     0.33972,     0.33939,     0.33858,     0.33725,     0.33584,      0.3352,     0.33504,     0.33472,     0.33433,     0.33322,     0.33165,      0.3313,     0.33096,     0.32935,     0.32628,     0.32576,     0.32364,     0.32278,     0.32187,\n",
       "            0.32139,       0.321,     0.32097,     0.31975,     0.31937,     0.31935,     0.31855,     0.31807,     0.31812,     0.31716,     0.31647,     0.31556,     0.31441,     0.31383,      0.3133,     0.31288,     0.31295,     0.31246,     0.31231,     0.31094,     0.30954,     0.30714,       0.307,\n",
       "            0.30707,      0.3063,     0.30593,       0.305,     0.30414,     0.30274,     0.30122,     0.30041,     0.30024,      0.2998,      0.2991,     0.29734,     0.29605,     0.29545,     0.29486,     0.29265,     0.29259,     0.29223,      0.2916,     0.28909,     0.28788,     0.28688,     0.28664,\n",
       "            0.28434,     0.28309,     0.28098,     0.28104,     0.28109,      0.2801,     0.27989,     0.27647,     0.27604,     0.27531,     0.27401,     0.27279,     0.26889,     0.26834,     0.26806,     0.26777,     0.26713,     0.26545,     0.26452,     0.26319,     0.26269,      0.2608,     0.25826,\n",
       "            0.25762,     0.25768,     0.25697,     0.25705,     0.25487,     0.25495,      0.2547,      0.2544,     0.25431,     0.25366,     0.25304,     0.25174,     0.25139,     0.25115,     0.25092,     0.25059,     0.25023,     0.24954,     0.24924,     0.24893,      0.2484,     0.24676,     0.24523,\n",
       "            0.24471,     0.24353,     0.24196,     0.24037,     0.23937,     0.23947,     0.23879,     0.23787,     0.23673,     0.23636,     0.23528,     0.23229,     0.23252,     0.23192,     0.23197,     0.23057,     0.22959,      0.2286,     0.22756,     0.22709,       0.227,     0.22476,     0.22405,\n",
       "            0.22337,     0.22216,     0.22124,     0.22111,     0.22127,     0.22141,      0.2215,     0.22016,     0.21939,     0.21773,      0.2174,     0.21707,     0.21672,     0.21637,     0.21635,     0.21651,     0.21655,     0.21552,     0.21267,     0.21285,     0.21041,     0.20902,     0.20788,\n",
       "            0.20754,     0.20501,     0.20464,     0.20427,     0.20302,     0.20181,     0.20148,     0.20115,     0.20017,     0.19975,     0.19871,     0.19813,     0.19673,     0.19533,     0.19323,     0.19246,     0.19166,     0.19088,     0.19037,     0.18981,     0.18883,     0.18793,     0.18801,\n",
       "            0.18804,     0.18808,     0.18815,     0.18685,     0.18484,     0.18421,     0.18363,     0.18277,     0.18129,     0.18065,      0.1803,     0.17837,     0.17788,     0.17737,     0.17683,     0.17478,      0.1743,     0.17397,     0.17364,     0.17333,     0.17304,     0.17272,     0.17224,\n",
       "            0.16998,     0.16956,     0.16959,     0.16957,      0.1694,     0.16924,     0.16907,     0.16891,     0.16843,     0.16738,     0.16646,     0.16501,     0.16384,     0.16276,     0.16244,      0.1615,     0.16111,     0.16071,     0.15979,     0.15844,     0.15786,     0.15707,     0.15657,\n",
       "            0.15545,     0.15516,     0.15487,     0.15448,      0.1539,     0.15187,     0.15107,      0.1502,     0.14971,      0.1491,     0.14814,     0.14616,     0.14541,     0.14488,     0.14435,     0.14389,     0.14318,     0.14238,     0.13911,     0.13766,     0.13709,      0.1361,     0.13419,\n",
       "            0.13318,     0.13067,     0.13034,     0.13001,      0.1289,     0.12839,     0.12664,     0.12619,     0.12589,     0.12559,     0.12432,     0.12384,     0.12291,     0.12266,      0.1224,     0.12215,     0.12086,     0.12023,     0.11938,      0.1192,     0.11902,     0.11884,     0.11865,\n",
       "            0.11836,     0.11798,     0.11751,     0.11648,      0.1151,     0.11333,     0.11142,     0.11104,      0.1107,     0.11074,     0.11026,     0.10969,     0.10921,     0.10795,     0.10721,     0.10591,     0.10476,     0.10342,     0.10302,     0.10242,     0.10161,     0.10112,     0.10076,\n",
       "            0.10046,     0.10017,     0.10006,     0.10007,     0.10009,    0.098971,    0.098282,    0.097876,     0.09747,    0.095988,    0.091985,    0.091425,     0.08861,    0.088008,    0.087633,     0.08746,    0.087475,     0.08749,    0.085941,    0.085142,    0.083872,    0.083338,    0.082242,\n",
       "           0.081154,    0.081166,    0.081178,    0.080707,    0.079533,    0.079387,    0.079015,    0.078637,    0.078119,    0.076964,     0.07571,    0.075724,    0.075738,     0.07561,    0.075407,    0.075204,    0.075001,    0.074792,    0.074534,    0.074275,    0.074016,    0.073628,    0.073127,\n",
       "           0.072457,    0.071902,    0.071583,    0.071263,    0.070313,    0.069319,    0.069082,    0.068732,    0.068403,    0.068348,    0.067417,    0.066868,     0.06612,      0.0655,     0.06523,    0.064961,    0.064642,    0.063567,    0.063076,    0.062713,    0.062475,    0.062237,       0.062,\n",
       "           0.061445,    0.060874,    0.060662,    0.060449,    0.060237,    0.060024,    0.059631,    0.059232,    0.057038,     0.05495,    0.053951,    0.053229,    0.051795,     0.05108,    0.050276,    0.048471,    0.048189,    0.047907,    0.046563,    0.045999,    0.044392,    0.043796,    0.043455,\n",
       "           0.043113,     0.04271,    0.042262,    0.041372,      0.0401,    0.039984,     0.03987,    0.039755,    0.039641,    0.039527,    0.039412,    0.039298,    0.039184,    0.037702,    0.036716,    0.035975,    0.035254,    0.034801,    0.034347,    0.033755,    0.033149,    0.032528,     0.03217,\n",
       "           0.031879,    0.031588,     0.03129,    0.030984,    0.030677,    0.028524,      0.0284,    0.028275,    0.028151,    0.028027,    0.027902,    0.027777,    0.027653,    0.027514,     0.02733,    0.027146,    0.026962,    0.026778,    0.026595,    0.026485,    0.026378,    0.026271,    0.026165,\n",
       "           0.026058,    0.025951,    0.025844,    0.025737,     0.02563,    0.025407,    0.025166,    0.024925,    0.024683,    0.024492,    0.024311,    0.024129,    0.023948,    0.023767,    0.022116,    0.021521,    0.021233,    0.020945,    0.019969,    0.019695,    0.019621,    0.019547,    0.019474,\n",
       "             0.0194,    0.019326,    0.019253,    0.019179,    0.019105,    0.019031,    0.018958,    0.018884,     0.01881,    0.018452,    0.017937,    0.017732,    0.017634,    0.017537,     0.01744,    0.017342,    0.017245,    0.017147,     0.01705,    0.016953,    0.016855,    0.016403,    0.015818,\n",
       "           0.015581,    0.015344,    0.015107,     0.01487,    0.014471,    0.014064,    0.013705,    0.013388,    0.013071,    0.012872,     0.01283,    0.012788,    0.012745,    0.012703,    0.012661,    0.012619,    0.012576,    0.012534,    0.012492,    0.012449,    0.012407,    0.012365,    0.012323,\n",
       "            0.01228,    0.012238,    0.012196,    0.012153,    0.012111,    0.012069,    0.012027,    0.011984,    0.011942,    0.011873,     0.01161,    0.011346,    0.011083,    0.010854,    0.010682,     0.01051,    0.010338,    0.010165,   0.0099934,   0.0088989,   0.0087268,   0.0085546,   0.0083824,\n",
       "          0.0082101,   0.0080379,   0.0078291,   0.0075843,   0.0073394,   0.0070945,   0.0069393,   0.0068902,   0.0068412,   0.0067921,   0.0067431,   0.0066941,    0.006645,    0.006596,   0.0065469,   0.0064979,   0.0064488,   0.0063997,   0.0063507,   0.0063016,   0.0062526,   0.0062035,   0.0061544,\n",
       "          0.0061053,   0.0060563,   0.0060072,   0.0059272,   0.0057521,    0.005577,   0.0054019,   0.0052267,   0.0050515,   0.0047441,   0.0043402,   0.0039153,   0.0033352,   0.0029506,   0.0028543,   0.0027579,   0.0026615,   0.0025652,   0.0024688,   0.0023724,    0.002276,   0.0021796,   0.0020832,\n",
       "          0.0019359,   0.0011603,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.081583,    0.081583,    0.081583,    0.081583,    0.081583,    0.081583,    0.081583,    0.081583,     0.08202,    0.083927,    0.090656,     0.11247,     0.14224,     0.15595,     0.16554,     0.17484,     0.18425,     0.19203,     0.19999,     0.20846,     0.21572,     0.22322,     0.23113,\n",
       "            0.23797,     0.24579,      0.2523,     0.25852,     0.26574,     0.27267,     0.27901,     0.28359,     0.29117,     0.29596,      0.3009,     0.30601,     0.31078,     0.31611,     0.32312,     0.32861,     0.33437,     0.33929,     0.34469,     0.34855,     0.35459,     0.36067,     0.36478,\n",
       "            0.36804,     0.37266,     0.37611,      0.3811,     0.38609,     0.39141,      0.3958,      0.4004,     0.40513,     0.40807,     0.41144,      0.4158,     0.41856,     0.42283,     0.42569,     0.43086,      0.4352,     0.44104,     0.44638,      0.4511,     0.45341,     0.45747,     0.46112,\n",
       "            0.46516,     0.46844,     0.47139,     0.47246,     0.47389,     0.47763,     0.48218,     0.48771,     0.49212,     0.49613,     0.49718,      0.5015,     0.50541,     0.50969,     0.51327,     0.51525,     0.51839,     0.52207,     0.52697,     0.52998,      0.5328,     0.53627,     0.53816,\n",
       "            0.53951,     0.54148,     0.54369,     0.54602,     0.54681,     0.55201,      0.5556,      0.5606,     0.56244,     0.56444,     0.56873,     0.57084,     0.57603,     0.57738,     0.58001,     0.58351,      0.5858,      0.5888,     0.59054,     0.59435,     0.59738,      0.5983,     0.59848,\n",
       "            0.59825,      0.5995,     0.60254,     0.60547,      0.6064,     0.60729,     0.60944,     0.61281,     0.61477,     0.61697,     0.62201,     0.62403,     0.62704,     0.62709,      0.6288,     0.63076,     0.63175,      0.6352,     0.63605,     0.64028,     0.64189,     0.64517,     0.64724,\n",
       "            0.64818,     0.65474,     0.65533,     0.65699,     0.65781,     0.66143,      0.6624,     0.66419,     0.66466,     0.66497,     0.66525,     0.66652,     0.66785,     0.66818,     0.66844,     0.67038,     0.67264,     0.67273,     0.67633,       0.678,     0.68204,     0.68376,     0.68647,\n",
       "            0.68779,     0.68804,       0.689,     0.68902,     0.68921,     0.68805,     0.68901,     0.68998,     0.68977,     0.69482,     0.69469,     0.69456,     0.69487,     0.69581,     0.69556,     0.69581,     0.69714,     0.70022,     0.70074,      0.7008,     0.70429,     0.70519,     0.70521,\n",
       "             0.7077,     0.70987,     0.71138,     0.71379,     0.71574,     0.71788,     0.71889,     0.71861,      0.7186,     0.71838,     0.71992,      0.7196,     0.71959,     0.72084,     0.72162,     0.72222,     0.72251,     0.72557,     0.72576,     0.72542,     0.72589,     0.72756,     0.73231,\n",
       "            0.73232,     0.73373,     0.73434,     0.73494,     0.73594,     0.73774,     0.73871,     0.74076,     0.74329,     0.74424,     0.74576,     0.75012,      0.7513,     0.75271,     0.75356,     0.75405,     0.75629,     0.75687,     0.75779,      0.7605,     0.76378,     0.76354,     0.76542,\n",
       "            0.76713,     0.76684,     0.76647,     0.76676,     0.76636,     0.76911,     0.76952,      0.7691,     0.76819,     0.76886,     0.76857,     0.76843,     0.76939,     0.77037,     0.76993,     0.76968,     0.77504,     0.77459,     0.77418,     0.77309,     0.77566,     0.77694,     0.77773,\n",
       "            0.77919,     0.78068,     0.78043,     0.78156,     0.78246,     0.78231,     0.78582,     0.78559,      0.7857,     0.78552,     0.78497,     0.78467,      0.7858,     0.78421,      0.7854,     0.78525,     0.78499,     0.78468,     0.78626,      0.7857,     0.78772,     0.78691,     0.79264,\n",
       "            0.79329,     0.79377,     0.79308,     0.79375,     0.79471,     0.79736,     0.79815,     0.79848,     0.79907,     0.80134,     0.80102,     0.79997,     0.79975,     0.79924,     0.79909,     0.79893,     0.80013,     0.79928,     0.79904,     0.80025,     0.80137,     0.80117,     0.80177,\n",
       "             0.8028,     0.80676,     0.80744,     0.80726,      0.8086,     0.80842,     0.80798,     0.80724,     0.80938,      0.8105,     0.81183,     0.81172,      0.8115,     0.81239,     0.81153,     0.81235,     0.81417,     0.81481,     0.81312,     0.81283,      0.8132,     0.81428,     0.81388,\n",
       "            0.81604,     0.81805,     0.81895,      0.8198,     0.82038,     0.82317,      0.8232,     0.82294,       0.824,     0.82409,     0.82538,     0.82488,     0.82426,     0.82394,     0.82365,     0.82373,     0.82479,     0.82488,     0.82649,     0.82574,     0.82497,     0.82364,     0.82429,\n",
       "            0.82531,      0.8249,      0.8247,     0.82592,     0.82544,     0.82466,      0.8238,     0.82869,      0.8327,     0.83381,     0.83342,     0.83246,     0.83174,     0.83141,     0.83108,     0.82984,     0.83168,     0.83147,     0.83112,      0.8297,     0.82901,     0.83034,     0.83179,\n",
       "            0.83081,     0.83008,     0.82897,     0.82991,     0.83086,      0.8303,     0.83394,     0.83216,     0.83394,     0.83351,     0.83275,     0.83203,     0.82969,     0.82936,     0.82919,     0.82901,     0.82862,     0.82758,       0.827,     0.82617,     0.82586,     0.82466,     0.82303,\n",
       "            0.82353,     0.82479,     0.82467,     0.82642,     0.82552,     0.82721,     0.82723,     0.82704,     0.82878,     0.83022,     0.83226,     0.83203,      0.8318,     0.83165,     0.83151,      0.8313,     0.83107,     0.83752,     0.83733,     0.83714,     0.83681,     0.83712,     0.83715,\n",
       "            0.83682,     0.83607,     0.83506,     0.83403,     0.83472,     0.83719,     0.84278,     0.84221,     0.84197,     0.84375,     0.84307,       0.842,     0.84903,      0.8518,     0.85328,      0.8531,     0.85249,     0.85188,     0.85123,     0.85636,     0.86068,     0.86148,     0.86571,\n",
       "            0.86531,      0.8646,     0.86405,     0.86536,     0.87032,      0.8748,     0.87767,     0.87814,     0.88075,     0.88292,     0.88274,     0.88256,     0.88238,     0.88219,     0.88424,     0.88945,     0.89102,     0.89117,     0.89023,     0.89675,     0.89842,     0.89774,     0.89718,\n",
       "            0.89701,     0.89574,     0.89555,     0.89536,     0.89472,     0.89409,     0.89392,     0.89375,     0.89673,     0.89652,     0.89953,     0.90283,     0.90214,     0.90144,     0.90408,     0.91125,     0.91087,     0.91051,     0.91026,        0.91,     0.90953,     0.90977,     0.91318,\n",
       "            0.91493,     0.91669,     0.92016,     0.92049,     0.91961,     0.91933,     0.91907,     0.91868,     0.91801,     0.91772,     0.91756,     0.91666,     0.91643,     0.91619,     0.91593,     0.91494,     0.92339,     0.92324,     0.92309,     0.92296,     0.92282,     0.92268,     0.92246,\n",
       "            0.92142,      0.9269,     0.92892,     0.93033,     0.93026,     0.93019,     0.93012,     0.93005,     0.92985,     0.92941,     0.92901,     0.92838,     0.93136,     0.93218,     0.93205,     0.93164,     0.93638,     0.93622,     0.93585,     0.93529,     0.93505,     0.93472,     0.93451,\n",
       "            0.93403,      0.9339,     0.93378,     0.93361,     0.93335,     0.93245,     0.93209,      0.9317,     0.93147,     0.93119,     0.93074,      0.9298,     0.93428,     0.93466,     0.93442,     0.93421,     0.93388,     0.93351,     0.93194,     0.93122,     0.93094,     0.93044,     0.92945,\n",
       "            0.92892,     0.92756,     0.92738,      0.9272,     0.92657,     0.92628,     0.92528,     0.92502,     0.92484,     0.92466,      0.9239,     0.92361,     0.92305,     0.92289,     0.92273,     0.92257,     0.92176,     0.92136,     0.92081,     0.92069,     0.92057,     0.92046,     0.92034,\n",
       "            0.92014,     0.91989,     0.91958,     0.91888,      0.9225,     0.92365,     0.92237,     0.92211,     0.92238,     0.92788,     0.92883,     0.92846,     0.92816,     0.92733,     0.92684,     0.92596,     0.92517,     0.92422,     0.92394,      0.9235,     0.92291,     0.92255,     0.92227,\n",
       "            0.92205,     0.92183,     0.92323,     0.92572,     0.92821,     0.92904,     0.92856,     0.92827,     0.92798,     0.92689,     0.92381,     0.92335,     0.92101,     0.92048,     0.92016,     0.92171,       0.925,      0.9283,     0.92805,      0.9274,     0.93175,     0.93576,     0.93492,\n",
       "            0.93623,     0.93943,     0.94263,     0.94412,     0.94331,     0.95386,     0.95381,     0.95359,     0.95328,     0.95259,      0.9527,     0.95727,     0.96183,     0.96335,     0.96325,     0.96315,     0.96305,     0.96295,     0.96282,     0.96269,     0.96256,     0.96236,      0.9621,\n",
       "            0.96175,     0.96146,     0.96129,     0.96112,     0.96059,     0.98176,     0.98625,     0.98618,     0.98685,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.48852,     0.48852,     0.48852,     0.48852,     0.48852,     0.48852,     0.48852,     0.48852,     0.48852,     0.48852,     0.48802,     0.48603,     0.48453,     0.48154,     0.47754,     0.47555,     0.47455,     0.47156,     0.47006,     0.46856,     0.46557,     0.46416,     0.46257,\n",
       "            0.46108,     0.46058,     0.45958,     0.45659,     0.45559,     0.45459,     0.45309,      0.4521,      0.4516,      0.4501,      0.4496,      0.4496,     0.44711,     0.44711,     0.44661,     0.44561,     0.44561,     0.44411,     0.44361,     0.44212,     0.43912,     0.43862,      0.4367,\n",
       "            0.43413,     0.43263,     0.43014,     0.42914,     0.42814,     0.42715,     0.42615,     0.42365,     0.42315,     0.42002,     0.41766,     0.41617,     0.41367,     0.41218,     0.41018,     0.40818,     0.40719,     0.40719,     0.40669,     0.40669,     0.40619,     0.40569,     0.40519,\n",
       "            0.40519,     0.40469,     0.40361,     0.40269,      0.4007,      0.4007,      0.3997,      0.3987,      0.3982,      0.3977,     0.39271,     0.39271,     0.39172,     0.39072,     0.39072,     0.38872,     0.38723,     0.38623,     0.38623,     0.38623,     0.38523,     0.38373,     0.38273,\n",
       "            0.38124,     0.37974,     0.37774,      0.3769,     0.37425,     0.37384,     0.37226,     0.37176,     0.37176,     0.37026,     0.36976,     0.36926,     0.36876,     0.36727,     0.36727,     0.36677,     0.36577,     0.36527,     0.36477,     0.36377,     0.36228,     0.36047,        0.36,\n",
       "             0.3589,     0.35779,     0.35729,      0.3561,     0.35529,     0.35329,     0.35279,     0.35279,     0.35278,      0.3513,      0.3498,      0.3498,       0.349,      0.3474,     0.34681,     0.34631,     0.34431,     0.34281,     0.34032,     0.34032,     0.33989,     0.33982,     0.33876,\n",
       "            0.33832,     0.33782,     0.33782,     0.33738,     0.33633,     0.33535,     0.33184,     0.33134,     0.33034,     0.32884,     0.32784,     0.32685,     0.32635,     0.32535,     0.32485,     0.32335,     0.32195,     0.32136,     0.32114,     0.32086,     0.32005,     0.31937,     0.31903,\n",
       "            0.31886,     0.31806,     0.31728,     0.31621,     0.31538,     0.31148,     0.30938,     0.30888,     0.30843,     0.30788,     0.30769,      0.3075,     0.30739,     0.30704,     0.30554,     0.30476,     0.30439,     0.30421,      0.3038,     0.30339,      0.3014,     0.30079,      0.3004,\n",
       "             0.2999,     0.29912,     0.29888,      0.2984,      0.2984,      0.2984,     0.29734,     0.29641,     0.29436,     0.29404,     0.29391,     0.29326,     0.29192,     0.29042,     0.28975,     0.28932,     0.28844,     0.28693,     0.28657,     0.28477,     0.28412,     0.28393,     0.28257,\n",
       "            0.28094,     0.28051,     0.28044,     0.27949,     0.27894,     0.27894,     0.27794,     0.27661,     0.27596,     0.27595,     0.27518,     0.27395,     0.27395,     0.27295,     0.27246,     0.27232,     0.27099,     0.27029,     0.26946,     0.26946,     0.26946,     0.26908,     0.26866,\n",
       "            0.26794,     0.26752,     0.26647,     0.26575,     0.26516,     0.26447,     0.26323,     0.26261,     0.26127,     0.26098,     0.26017,     0.25948,     0.25798,     0.25781,     0.25717,     0.25499,     0.25499,     0.25378,     0.25318,     0.25162,        0.25,      0.2495,     0.24794,\n",
       "             0.2475,     0.24689,     0.24601,     0.24601,     0.24589,     0.24501,      0.2435,     0.24251,      0.2415,     0.24124,     0.24045,     0.24002,     0.24002,     0.23756,     0.23752,     0.23721,     0.23684,     0.23641,     0.23496,     0.23417,     0.23331,     0.23218,      0.2308,\n",
       "            0.23004,     0.22856,      0.2276,     0.22754,     0.22754,     0.22754,     0.22754,     0.22737,     0.22705,     0.22543,     0.22498,     0.22352,     0.22321,      0.2225,     0.22228,     0.22207,     0.22174,     0.22056,     0.22023,      0.2199,     0.21944,     0.21917,     0.21707,\n",
       "            0.21657,     0.21607,     0.21552,     0.21526,     0.21503,     0.21478,     0.21416,     0.21315,     0.21188,     0.21129,     0.21108,     0.21083,     0.21053,      0.2096,     0.20841,     0.20808,      0.2077,     0.20639,     0.20409,      0.2037,     0.20202,     0.20128,      0.2006,\n",
       "             0.2001,     0.19967,      0.1996,      0.1986,     0.19828,      0.1981,     0.19749,     0.19713,     0.19711,     0.19636,     0.19577,      0.1951,     0.19425,     0.19383,     0.19344,     0.19311,     0.19311,     0.19273,     0.19253,     0.19153,     0.19051,     0.18876,     0.18862,\n",
       "            0.18862,     0.18807,      0.1878,     0.18704,     0.18641,      0.1854,      0.1843,     0.18346,     0.18313,     0.18276,     0.18225,       0.181,     0.18007,     0.17964,     0.17922,     0.17765,     0.17752,     0.17726,     0.17682,     0.17504,     0.17419,     0.17339,     0.17315,\n",
       "            0.17152,     0.17064,     0.16916,     0.16916,     0.16916,     0.16846,     0.16816,     0.16577,     0.16539,     0.16489,     0.16398,     0.16314,     0.16045,     0.16007,     0.15987,     0.15967,     0.15923,     0.15807,     0.15744,     0.15653,     0.15619,      0.1549,     0.15316,\n",
       "            0.15269,     0.15269,      0.1522,      0.1522,      0.1507,      0.1507,     0.15052,     0.15032,      0.1502,      0.1497,      0.1492,     0.14831,     0.14807,     0.14791,     0.14775,     0.14753,     0.14729,     0.14661,     0.14641,      0.1462,     0.14585,     0.14471,     0.14365,\n",
       "            0.14331,     0.14252,     0.14147,     0.14042,     0.13972,     0.13972,      0.1391,      0.1385,     0.13772,     0.13743,     0.13672,     0.13473,     0.13471,     0.13423,     0.13423,      0.1333,     0.13266,     0.13201,     0.13134,      0.1309,     0.13074,     0.12924,     0.12868,\n",
       "            0.12824,     0.12746,     0.12686,     0.12675,     0.12675,     0.12675,     0.12675,     0.12586,      0.1253,     0.12418,     0.12397,     0.12376,     0.12353,     0.12331,     0.12325,     0.12325,     0.12325,     0.12258,     0.12076,     0.12076,     0.11916,     0.11828,     0.11756,\n",
       "            0.11734,     0.11575,     0.11552,     0.11529,      0.1145,     0.11374,     0.11353,     0.11333,     0.11266,      0.1124,     0.11169,     0.11128,      0.1104,     0.10953,     0.10817,     0.10759,      0.1071,     0.10662,      0.1063,     0.10596,     0.10535,     0.10479,     0.10479,\n",
       "            0.10479,     0.10479,     0.10479,     0.10398,     0.10274,     0.10236,     0.10201,     0.10148,     0.10057,     0.10018,    0.099972,    0.098798,    0.098499,     0.09819,     0.09786,    0.096619,    0.096235,    0.096033,    0.095831,    0.095649,    0.095469,    0.095278,     0.09499,\n",
       "           0.093626,    0.093313,    0.093313,    0.093284,    0.093185,    0.093086,    0.092987,    0.092888,    0.092605,    0.091975,     0.09142,    0.090553,     0.08982,    0.089162,    0.088975,    0.088413,    0.088139,    0.087897,    0.087351,    0.086553,    0.086206,    0.085737,    0.085443,\n",
       "           0.084778,    0.084609,     0.08444,    0.084208,    0.083862,    0.082664,    0.082195,    0.081683,    0.081394,    0.081037,    0.080474,    0.079314,    0.078842,    0.078523,    0.078215,    0.077946,    0.077533,     0.07707,    0.075165,    0.074321,     0.07399,     0.07342,    0.072315,\n",
       "           0.071734,    0.070288,    0.070098,    0.069908,    0.069267,    0.068973,    0.067972,    0.067714,    0.067541,    0.067367,    0.066645,    0.066368,     0.06584,    0.065694,    0.065549,    0.065403,    0.064668,    0.064311,    0.063826,    0.063723,    0.063621,    0.063518,    0.063415,\n",
       "           0.063247,    0.063033,    0.062764,     0.06218,    0.061377,    0.060367,    0.059291,    0.059077,    0.058882,    0.058882,     0.05861,    0.058288,     0.05802,    0.057313,    0.056897,    0.056166,    0.055523,    0.054775,    0.054552,    0.054218,    0.053763,    0.053494,     0.05329,\n",
       "           0.053125,     0.05296,    0.052894,    0.052894,    0.052894,     0.05227,    0.051887,    0.051662,    0.051437,    0.050615,    0.048402,    0.048093,    0.046544,    0.046213,    0.046007,    0.045908,    0.045908,    0.045908,    0.045057,    0.044619,    0.043912,    0.043611,    0.043013,\n",
       "           0.042415,    0.042415,    0.042415,    0.042155,    0.041516,    0.041417,    0.041215,    0.041009,    0.040728,    0.040102,    0.039421,    0.039421,    0.039421,    0.039349,     0.03924,     0.03913,     0.03902,    0.038907,    0.038767,    0.038628,    0.038488,    0.038278,    0.038008,\n",
       "           0.037646,    0.037348,    0.037176,    0.037004,    0.036492,    0.035928,    0.035795,    0.035607,    0.035429,    0.035383,    0.034885,    0.034591,     0.03419,    0.033859,    0.033715,    0.033571,    0.033401,    0.032827,    0.032565,    0.032371,    0.032245,    0.032118,    0.031991,\n",
       "           0.031696,    0.031393,     0.03128,    0.031167,    0.031054,    0.030941,    0.030732,     0.03052,    0.029356,    0.028251,    0.027723,    0.027342,    0.026586,    0.026209,    0.025786,    0.024838,    0.024689,    0.024541,    0.023836,    0.023541,      0.0227,    0.022388,     0.02221,\n",
       "           0.022032,    0.021821,    0.021587,    0.021123,     0.02046,      0.0204,     0.02034,    0.020281,    0.020221,    0.020162,    0.020102,    0.020043,    0.019983,    0.019213,    0.018702,    0.018317,    0.017944,    0.017709,    0.017474,    0.017167,    0.016854,    0.016533,    0.016348,\n",
       "           0.016198,    0.016047,    0.015894,    0.015736,    0.015578,    0.014469,    0.014405,     0.01434,    0.014276,    0.014212,    0.014148,    0.014084,     0.01402,    0.013949,    0.013854,     0.01376,    0.013665,    0.013571,    0.013476,     0.01342,    0.013365,    0.013311,    0.013256,\n",
       "           0.013201,    0.013146,    0.013091,    0.013036,    0.012982,    0.012867,    0.012743,     0.01262,    0.012496,    0.012398,    0.012305,    0.012212,    0.012119,    0.012026,    0.011181,    0.010878,     0.01073,    0.010583,    0.010085,   0.0099454,   0.0099078,   0.0098702,   0.0098326,\n",
       "          0.0097951,   0.0097575,   0.0097199,   0.0096823,   0.0096447,   0.0096072,   0.0095696,    0.009532,   0.0094944,   0.0093121,   0.0090497,   0.0089452,   0.0088957,   0.0088461,   0.0087966,    0.008747,   0.0086974,   0.0086479,   0.0085983,   0.0085487,   0.0084992,   0.0082695,   0.0079722,\n",
       "          0.0078518,   0.0077315,   0.0076111,   0.0074908,   0.0072883,   0.0070817,   0.0068998,    0.006739,   0.0065783,   0.0064778,   0.0064564,    0.006435,   0.0064136,   0.0063922,   0.0063708,   0.0063493,   0.0063279,   0.0063065,   0.0062851,   0.0062637,   0.0062423,   0.0062209,   0.0061995,\n",
       "          0.0061781,   0.0061567,   0.0061353,   0.0061139,   0.0060925,   0.0060711,   0.0060497,   0.0060283,   0.0060069,    0.005972,   0.0058388,   0.0057055,   0.0055723,   0.0054564,   0.0053695,   0.0052826,   0.0051956,   0.0051087,   0.0050218,   0.0044694,   0.0043825,   0.0042957,   0.0042088,\n",
       "           0.004122,   0.0040351,   0.0039299,   0.0038066,   0.0036832,   0.0035599,   0.0034817,    0.003457,   0.0034323,   0.0034076,    0.003383,   0.0033583,   0.0033336,   0.0033089,   0.0032842,   0.0032595,   0.0032348,   0.0032101,   0.0031855,   0.0031608,   0.0031361,   0.0031114,   0.0030867,\n",
       "           0.003062,   0.0030373,   0.0030126,   0.0029724,   0.0028843,   0.0027963,   0.0027082,   0.0026202,   0.0025321,   0.0023777,   0.0021748,   0.0019615,   0.0016704,   0.0014775,   0.0014292,   0.0013809,   0.0013325,   0.0012842,   0.0012359,   0.0011876,   0.0011393,    0.001091,   0.0010427,\n",
       "         0.00096887,  0.00058048,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.1782749814880986)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.15721])\n",
       "names: {0: 'Whitefly'}\n",
       "nt_per_class: array([2004])\n",
       "nt_per_image: array([40])\n",
       "results_dict: {'metrics/precision(B)': np.float64(0.5994993623834641), 'metrics/recall(B)': np.float64(0.35778597416911045), 'metrics/mAP50(B)': np.float64(0.36785969432163146), 'metrics/mAP50-95(B)': np.float64(0.15721001339548382), 'fitness': np.float64(0.1782749814880986)}\n",
       "save_dir: PosixPath('example_simple_detector/yolov11n_custom')\n",
       "speed: {'preprocess': 0.5411384999888469, 'inference': 40.92352499997105, 'loss': 0.00013434998891170835, 'postprocess': 10.130518749997464}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import train_yolo\n",
    "\n",
    "project = \"example_simple_detector\" # Project directory for saving results\n",
    "\n",
    "name = \"yolov11n_custom\"\n",
    "\n",
    "# Train the YOLO model\n",
    "trained = train_yolo(\n",
    "    img=608, # Image size\n",
    "    epochs=5, # Number of epochs\n",
    "    data=\"dataset/data.yaml\", # Path to data configuration file\n",
    "    weights=\"yolo11n.pt\", # Pre-trained weights from COCO dataset\n",
    "    batch=4, # Batch size\n",
    "    name=name, # Name of the training run\n",
    "    project=project # Project directory for saving results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b4ab55",
   "metadata": {},
   "source": [
    "### Step 3: Detection with the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9221309",
   "metadata": {},
   "source": [
    "Once your model has been trained, you can use it to detect objects in new images.\n",
    "\n",
    "Below is an example of how to **load your trained YOLOv11 model**, run inference on a single image, and **visualize the results** using `OpenCV` and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b017991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ‚ö†Ô∏è \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 6 Whiteflys, 37.8ms\n",
      "video 1/1 (frame 2/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 35.0ms\n",
      "video 1/1 (frame 3/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 33.9ms\n",
      "video 1/1 (frame 4/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 33.8ms\n",
      "video 1/1 (frame 5/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 33.4ms\n",
      "video 1/1 (frame 6/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 6 Whiteflys, 32.2ms\n",
      "video 1/1 (frame 7/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 6 Whiteflys, 36.1ms\n",
      "video 1/1 (frame 8/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 33.3ms\n",
      "video 1/1 (frame 9/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 34.3ms\n",
      "video 1/1 (frame 10/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 36.3ms\n",
      "video 1/1 (frame 11/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 33.6ms\n",
      "video 1/1 (frame 12/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 35.2ms\n",
      "video 1/1 (frame 13/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 31.8ms\n",
      "video 1/1 (frame 14/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 32.3ms\n",
      "video 1/1 (frame 15/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 32.5ms\n",
      "video 1/1 (frame 16/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 35.6ms\n",
      "video 1/1 (frame 17/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 11 Whiteflys, 34.8ms\n",
      "video 1/1 (frame 18/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 11 Whiteflys, 34.5ms\n",
      "video 1/1 (frame 19/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 11 Whiteflys, 33.4ms\n",
      "video 1/1 (frame 20/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 33.6ms\n",
      "video 1/1 (frame 21/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 6 Whiteflys, 34.4ms\n",
      "video 1/1 (frame 22/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 6 Whiteflys, 32.6ms\n",
      "video 1/1 (frame 23/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 32.4ms\n",
      "video 1/1 (frame 24/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 32.3ms\n",
      "video 1/1 (frame 25/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 32.0ms\n",
      "video 1/1 (frame 26/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 31.1ms\n",
      "video 1/1 (frame 27/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 31.1ms\n",
      "video 1/1 (frame 28/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 10 Whiteflys, 33.6ms\n",
      "video 1/1 (frame 29/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 32.2ms\n",
      "video 1/1 (frame 30/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 30.6ms\n",
      "video 1/1 (frame 31/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 10 Whiteflys, 31.8ms\n",
      "video 1/1 (frame 32/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 30.3ms\n",
      "video 1/1 (frame 33/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 10 Whiteflys, 33.3ms\n",
      "video 1/1 (frame 34/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 11 Whiteflys, 31.8ms\n",
      "video 1/1 (frame 35/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 31.9ms\n",
      "video 1/1 (frame 36/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 10 Whiteflys, 29.7ms\n",
      "video 1/1 (frame 37/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 10 Whiteflys, 32.7ms\n",
      "video 1/1 (frame 38/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 35.0ms\n",
      "video 1/1 (frame 39/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 5 Whiteflys, 30.0ms\n",
      "video 1/1 (frame 40/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 31.4ms\n",
      "video 1/1 (frame 41/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 31.6ms\n",
      "video 1/1 (frame 42/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 31.4ms\n",
      "video 1/1 (frame 43/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 33.5ms\n",
      "video 1/1 (frame 44/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 4 Whiteflys, 34.8ms\n",
      "video 1/1 (frame 45/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 5 Whiteflys, 30.2ms\n",
      "video 1/1 (frame 46/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 33.7ms\n",
      "video 1/1 (frame 47/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 33.2ms\n",
      "video 1/1 (frame 48/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 40.1ms\n",
      "video 1/1 (frame 49/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 5 Whiteflys, 32.5ms\n",
      "video 1/1 (frame 50/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 30.9ms\n",
      "video 1/1 (frame 51/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 5 Whiteflys, 31.7ms\n",
      "video 1/1 (frame 52/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 5 Whiteflys, 33.3ms\n",
      "video 1/1 (frame 53/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 6 Whiteflys, 32.1ms\n",
      "video 1/1 (frame 54/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 31.2ms\n",
      "video 1/1 (frame 55/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 31.8ms\n",
      "video 1/1 (frame 56/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 32.2ms\n",
      "video 1/1 (frame 57/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 32.0ms\n",
      "video 1/1 (frame 58/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 32.6ms\n",
      "video 1/1 (frame 59/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 33.4ms\n",
      "video 1/1 (frame 60/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 6 Whiteflys, 35.1ms\n",
      "video 1/1 (frame 61/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 6 Whiteflys, 33.3ms\n",
      "video 1/1 (frame 62/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 6 Whiteflys, 33.5ms\n",
      "video 1/1 (frame 63/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 30.5ms\n",
      "video 1/1 (frame 64/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 6 Whiteflys, 32.6ms\n",
      "video 1/1 (frame 65/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 5 Whiteflys, 31.5ms\n",
      "video 1/1 (frame 66/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 31.4ms\n",
      "video 1/1 (frame 67/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 31.0ms\n",
      "video 1/1 (frame 68/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 33.8ms\n",
      "video 1/1 (frame 69/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 42.7ms\n",
      "video 1/1 (frame 70/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 32.8ms\n",
      "video 1/1 (frame 71/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 6 Whiteflys, 31.7ms\n",
      "video 1/1 (frame 72/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 40.2ms\n",
      "video 1/1 (frame 73/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 37.0ms\n",
      "video 1/1 (frame 74/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 40.7ms\n",
      "video 1/1 (frame 75/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 37.7ms\n",
      "video 1/1 (frame 76/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 10 Whiteflys, 44.2ms\n",
      "video 1/1 (frame 77/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 11 Whiteflys, 44.6ms\n",
      "video 1/1 (frame 78/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 48.2ms\n",
      "video 1/1 (frame 79/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 11 Whiteflys, 36.7ms\n",
      "video 1/1 (frame 80/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 12 Whiteflys, 37.8ms\n",
      "video 1/1 (frame 81/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 37.1ms\n",
      "video 1/1 (frame 82/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 44.5ms\n",
      "video 1/1 (frame 83/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 6 Whiteflys, 38.5ms\n",
      "video 1/1 (frame 84/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 6 Whiteflys, 36.2ms\n",
      "video 1/1 (frame 85/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 8 Whiteflys, 33.8ms\n",
      "video 1/1 (frame 86/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 10 Whiteflys, 37.6ms\n",
      "video 1/1 (frame 87/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 33.4ms\n",
      "video 1/1 (frame 88/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 5 Whiteflys, 33.2ms\n",
      "video 1/1 (frame 89/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 35.3ms\n",
      "video 1/1 (frame 90/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 9 Whiteflys, 36.3ms\n",
      "video 1/1 (frame 91/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 34.9ms\n",
      "video 1/1 (frame 92/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 35.1ms\n",
      "video 1/1 (frame 93/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 7 Whiteflys, 32.1ms\n",
      "video 1/1 (frame 94/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 10 Whiteflys, 34.5ms\n",
      "video 1/1 (frame 95/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 352x608 6 Whiteflys, 33.2ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m file_to_detect \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexamples/example_video.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Path to the video file to detect objects in\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#file_to_detect = 'dataset/improved/2.jpg' # Path to the image file to detect objects in\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Run detection using the trained YOLO model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_yolo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_to_detect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Source file for detection\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mproject\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/weights/best.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Path to the best weights\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m608\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Image size for detection\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Path to the saved detection image\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# YOLO results are typically saved in 'runs/detect/<name>/image.jpg'\u001b[39;00m\n\u001b[1;32m     16\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msave_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file_to_detect))\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/utils/object_detection.py:50\u001b[0m, in \u001b[0;36mdetect_yolo\u001b[0;34m(img, source, name, project, weights)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdetect_yolo\u001b[39m(img\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1280\u001b[39m, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimgs/\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m'\u001b[39m, project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.temp/detect\u001b[39m\u001b[38;5;124m'\u001b[39m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolo11n.pt\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     49\u001b[0m     model \u001b[38;5;241m=\u001b[39m YOLO(weights)\n\u001b[0;32m---> 50\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_txt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_conf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/ultralytics/engine/model.py:185\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    158\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image\u001b[38;5;241m.\u001b[39mImage, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    159\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    161\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/ultralytics/engine/model.py:555\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/ultralytics/engine/predictor.py:227\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/torch/utils/_contextlib.py:57\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m             \u001b[38;5;66;03m# Pass the last request to the generator and get its response\u001b[39;00m\n\u001b[1;32m     56\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 57\u001b[0m                 response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# We let the exceptions raised above by the generator's `.throw` or\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# `.send` methods bubble up to our caller, except for StopIteration\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# The generator informed us that it is done: take whatever its\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# returned value (if any) was and indicate that we're done too\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# by returning it (see docs for python's return-statement).\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/ultralytics/engine/predictor.py:330\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 330\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/ultralytics/engine/predictor.py:182\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    178\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    181\u001b[0m )\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/ultralytics/nn/autobackend.py:640\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[0;32m--> 640\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/ultralytics/nn/tasks.py:138\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/ultralytics/nn/tasks.py:156\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/ultralytics/nn/tasks.py:179\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 179\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    180\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/ultralytics/nn/modules/conv.py:92\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     83\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils import detect_yolo\n",
    "import os\n",
    "\n",
    "file_to_detect = 'examples/example_video.mp4' # Path to the video file to detect objects in\n",
    "#file_to_detect = 'dataset/improved/2.jpg' # Path to the image file to detect objects in\n",
    "\n",
    "# Run detection using the trained YOLO model\n",
    "results = detect_yolo(\n",
    "    source=file_to_detect, # Source file for detection\n",
    "    weights=f\"{project}/{name}/weights/best.pt\", # Path to the best weights\n",
    "    img=608, # Image size for detection\n",
    ")\n",
    "\n",
    "# Path to the saved detection image\n",
    "# YOLO results are typically saved in 'runs/detect/<name>/image.jpg'\n",
    "output_path = os.path.join(results[0].save_dir, os.path.basename(file_to_detect))\n",
    "\n",
    "# Display detected image\n",
    "display(Image(filename=output_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc443367",
   "metadata": {},
   "source": [
    "## ü§ñ Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de08a0",
   "metadata": {},
   "source": [
    "The goal of **Active Learning (AL)** is to select the **most relevant samples** to be labeled first and used to train a model.  \n",
    "This approach is particularly useful when **labeling data is expensive or time-consuming**.\n",
    "\n",
    "Even with a **small initial set of labeled data**, it is possible to train a baseline model.  \n",
    "To improve the model further, we need more labeled data ‚Äî but instead of labeling everything, **Active Learning helps prioritize** which samples to label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea14083",
   "metadata": {},
   "source": [
    "### Active Learning Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10317689",
   "metadata": {},
   "source": [
    "There are two main approaches to Active Learning:\n",
    "\n",
    "#### Stream-Based Selective Sampling\n",
    "\n",
    "- Unlabeled data points are processed **one at a time**.\n",
    "- For each sample, the model must decide **immediately** whether to query its label or discard it.\n",
    "- Useful when data arrives in real time or memory is limited.\n",
    "\n",
    "#### Pool-Based Sampling\n",
    "\n",
    "- The model evaluates a **pool of unlabeled data** all at once.\n",
    "- Each sample is scored based on a **relevance criterion** (e.g., confidence, entropy).\n",
    "- The **top-K most informative** samples are selected and labeled.\n",
    "- This is the most commonly used method in practice.\n",
    "\n",
    "In Pool-based the process works as follows:\n",
    "\n",
    "##### 1. A model is trained on the current labeled dataset.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/al_1.png)\n",
    "\n",
    "##### 2. The model is then used to evaluate the **unlabeled data**.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/al_2.png)\n",
    "\n",
    "##### 3. Based on its predictions, the model **scores all unlabeled samples** using a selection strategy (e.g., uncertainty, disagreement, diversity).\n",
    "   - Samples are then **ranked** by relevance.\n",
    "   - Common scoring strategies include:\n",
    "     - **Uncertainty sampling**: Select samples with the lowest confidence (highest uncertainty).\n",
    "     - **Diversity sampling**: Choose a diverse set of samples to maximize information gain and avoid redundancy.\n",
    "     - **Representativeness**: Pick samples that best represent the distribution of the overall data.\n",
    "     - **Entropy-based sampling**: Select samples with the highest prediction entropy (more confusion between classes).\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/al_3.png)\n",
    "\n",
    "##### 4. Based on the ranking, the **top-K most relevant samples are selected, labeled by an expert, and added to the labeled set**.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/al_4.png)\n",
    "\n",
    "##### 5. This cycle repeats, improving the model efficiently while **minimizing annotation effort**.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/al_5.png)\n",
    "\n",
    "---\n",
    "\n",
    "By focusing labeling efforts on the **most informative samples**, Active Learning enables more efficient training and faster model improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be83b39",
   "metadata": {},
   "source": [
    "### Experiment Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc164d",
   "metadata": {},
   "source": [
    "In this section, we evaluate the impact of **Active Learning (AL)** in a Pool-based scenario by training and comparing **two models**:\n",
    "\n",
    "##### Incremental Training Strategy\n",
    "\n",
    "Both models are trained **incrementally**:\n",
    "\n",
    "- Training begins with a **small subset** of images for training and validation.\n",
    "- At each iteration, a **new batch of data** is added to the training and validation sets.\n",
    "- A new model is trained after each update.\n",
    "- This process is repeated for a fixed number of iterations, defined by the variable `num_batches`.\n",
    "\n",
    "The number of images added in each iteration is determined by:\n",
    "\n",
    "- `batch_train_proportion * dataset_size` for training images\n",
    "- `batch_val_proportion * dataset_size` for validation images\n",
    "\n",
    "---\n",
    "\n",
    "##### Model Variants\n",
    "\n",
    "- **Active Learning Model:**  \n",
    "  Selects new images based on **model uncertainty**, e.g., low confidence in predictions. This ensures the **most informative** samples are used in training in first place.\n",
    "\n",
    "- **Random Selection Model:**  \n",
    "  Selects new images **randomly** from the unlabeled pool at each iteration, serving as a baseline for comparison.\n",
    "\n",
    "---\n",
    "\n",
    "##### ‚öôÔ∏è Key Parameters\n",
    "\n",
    "- `num_batches`: Number of incremental iterations (rounds of training)\n",
    "- `batch_train_proportion`: Proportion of the dataset used for training in each batch\n",
    "- `batch_val_proportion`: Proportion of the dataset used for validation in each batch\n",
    "\n",
    "These parameters control **how much data is added per iteration** and ensure both models grow in training size at the same pace, allowing for a fair comparison.\n",
    "\n",
    "---\n",
    "\n",
    "üìà At the end of the experiment, we compare the models using their **mAP@50** scores across iterations to evaluate which strategy learns more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c01706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_split, split_dataset, new_batch, train_yolo, test_yolo\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# -------- Dataset setup --------\n",
    "# Define dataset parameters\n",
    "\n",
    "dataset_size = 200 # Total number of images in the dataset\n",
    "num_batches = 5 # Number of batches to process\n",
    "batch_train_prop = 0.6 / num_batches # Proportion of images in each batch for training (60% of the dataset)\n",
    "batch_val_prop = 0.2 / num_batches # Proportion of images in each batch for validation (20% of the dataset)\n",
    "\n",
    "num_epochs = 5 # Number of epochs for each training run\n",
    "batch_size = 4 # Batch size for training\n",
    "image_size = 608 # Image size for detection\n",
    "\n",
    "# Project base\n",
    "project = \"example_active_learning\" # Base project directory for saving results\n",
    "base_weights = \"yolo11n.pt\" # Pre-trained weights to start training from\n",
    "\n",
    "results_df = pd.DataFrame(index=range(num_batches)) # DataFrame to store results\n",
    "\n",
    "# -------- Initial split --------\n",
    "# Get initial train/val split for the first batch \n",
    "# this will ensure both models start with the same initial data\n",
    "initial_train_split, initial_val_split = get_split(\n",
    "                train_size=batch_train_prop,\n",
    "                val_size=batch_val_prop,\n",
    "                dataset_size=dataset_size\n",
    "            ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2575a42c",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154cdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>al mAP (test)</th>\n",
       "      <th>random mAP (test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.001031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156266</td>\n",
       "      <td>0.197514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.384305</td>\n",
       "      <td>0.372369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.455007</td>\n",
       "      <td>0.453421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.463545</td>\n",
       "      <td>0.484566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   al mAP (test)  random mAP (test)\n",
       "0       0.001031           0.001031\n",
       "1       0.156266           0.197514\n",
       "2       0.384305           0.372369\n",
       "3       0.455007           0.453421\n",
       "4       0.463545           0.484566"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Active Learning vs Random Selection (mAP@50)'}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a function to run a full mode (AL or random)\n",
    "def run_training_loop(mode=\"al\"):\n",
    "\n",
    "    for batch in range(num_batches): # Loop through each batch\n",
    "        print(f\"\\n=== Batch {batch} / {num_batches} ‚Äî Mode: {mode} ===\")\n",
    "        name = f\"{mode}_batch_{batch}\" # Name for the current batch run (directory)\n",
    "\n",
    "        if batch == 0: # First batch, use initial split\n",
    "            split_dataset(train_split=initial_train_split, val_split=initial_val_split)\n",
    "        else: # Subsequent batches, select new data\n",
    "            new_batch(\n",
    "                random=(mode == \"random\"), # Random selection if mode is \"random\"\n",
    "                al=\"confidence\", # Use confidence-based selection for active learning (other opriont: \"count\" - selected images with the most detections)\n",
    "                weights=weights, # Weights from the previous batch\n",
    "                train_images=int(batch_train_prop * dataset_size),\n",
    "                val_images=int(batch_val_prop * dataset_size),\n",
    "                project=f\"{project}_{mode}/detecting\",\n",
    "                name=name,\n",
    "                dataset=\"original\",\n",
    "                img_size=608\n",
    "            )\n",
    "        \n",
    "        # Train the YOLO model with the selected data\n",
    "        results = train_yolo(\n",
    "            img=image_size,\n",
    "            epochs=num_epochs,\n",
    "            data=\"dataset/data.yaml\",\n",
    "            weights=base_weights, # Use base weights for training (always start from scratch)\n",
    "            batch=batch_size,\n",
    "            name=name,\n",
    "            project=f\"{project}_{mode}/training\"\n",
    "        )\n",
    "\n",
    "        weights = f\"{project}_{mode}/training/{name}/weights/best.pt\" # Weights used to compute most relevant images in the next batch and for testing\n",
    "        test_results = test_yolo(\n",
    "            img=image_size,\n",
    "            data=\"dataset/data.yaml\",\n",
    "            weights=weights, # Weights from the model trained in this batch\n",
    "            project=f\"{project}_{mode}/testing\"\n",
    "        )\n",
    "        mAP_test = float(test_results.results_dict[\"metrics/mAP50(B)\"])\n",
    "        mAP = float(results.results_dict[\"metrics/mAP50(B)\"])\n",
    "        #results_df.loc[batch, f\"{mode}_mAP\"] = mAP\n",
    "        results_df.loc[batch, f\"{mode} mAP (test)\"] = mAP_test\n",
    "        print(f\"‚úÖ Batch {batch + 1} ({mode}) done ‚Äî mAP@50: {mAP:.4f}\")\n",
    "\n",
    "# Run both modes\n",
    "run_training_loop(mode=\"al\")\n",
    "run_training_loop(mode=\"random\")\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "# View combined results\n",
    "display(results_df)\n",
    "%matplotlib inline\n",
    "results_df.plot(title=\"Active Learning vs Random Selection (mAP@50)\", marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9080c338",
   "metadata": {},
   "source": [
    "## üßπ Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd8bedf",
   "metadata": {},
   "source": [
    "In object detection, **annotation quality** plays a critical role in model performance.\n",
    "\n",
    "Unlike classification tasks, object detection requires:\n",
    "- The correct **label** for each object\n",
    "- A precise **bounding box** tightly enclosing the object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c259abf",
   "metadata": {},
   "source": [
    "### Common Annotation Issues\n",
    "\n",
    "- **Incorrect Labels**: The object is mislabeled or assigned the wrong class.\n",
    "- **Poor Bounding Boxes**:\n",
    "  - Boxes do not align with the object\n",
    "  - Boxes are too loose or too tight\n",
    "  - Boxes include multiple objects\n",
    "- **Inconsistent Annotations** across similar samples\n",
    "\n",
    "Such errors often stem from:\n",
    "- **Repetitive labeling** tasks\n",
    "- **Fatigue** or insufficient training of annotators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e8398c",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/data_quality.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9377da",
   "metadata": {},
   "source": [
    "### Annotation Quality Example: Original vs Improved Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e038459",
   "metadata": {},
   "source": [
    "As an illustration of the importance of annotation quality, this notebook includes **two versions of the same dataset**:\n",
    "\n",
    "- `dataset/original/`: Contains the original annotations\n",
    "- `dataset/improved/`: Contains refined, higher-quality annotations\n",
    "\n",
    "Both versions share the **same images**, but differ in the accuracy and consistency of their bounding boxes and labels.\n",
    "\n",
    "This allows us to analyze:\n",
    "- How labeling precision impacts training performance\n",
    "- Whether better annotations lead to **higher mAP** and more reliable predictions\n",
    "\n",
    "By training the same model on each version, we can measure how much improvement is achieved **purely through better annotations** ‚Äî without changing the model architecture or training strategy.\n",
    "\n",
    "> This is especially useful in real-world projects, where annotation time is expensive, and correcting label errors can be more effective than adding more data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041edc76",
   "metadata": {},
   "source": [
    "#### Experimentation Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840a09f2",
   "metadata": {},
   "source": [
    "In this experiment, **two models are trained using the same set of images**, but with **different annotations**.  \n",
    "This setup is designed to evaluate the impact of **annotation quality** on the performance of an object detection model.\n",
    "\n",
    "- Both models share the **same training and validation splits**, ensuring a fair and controlled comparison.\n",
    "- The only difference lies in the annotations:\n",
    "  - One model uses the **original** annotation set.\n",
    "  - The other uses a set of **improved** annotations.\n",
    "\n",
    "---\n",
    "\n",
    "At the end of training, we compare the models using the **mAP@50 metric** to assess how annotation quality affects detection performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_split, split_dataset, train_yolo, test_yolo\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Get train/val split from dataset (test already fixed)\n",
    "train_split, val_split = get_split(\n",
    "    train_size=0.6,\n",
    "    val_size=0.2,\n",
    "    dataset_size=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef67c7c",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286bc7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_yolo(name):\n",
    "    # Train and test YOLO model with original annotations\n",
    "    train_yolo(\n",
    "        img=608,\n",
    "        epochs=5,\n",
    "        data=\"dataset/data.yaml\",\n",
    "        weights=\"yolo11n.pt\",\n",
    "        batch=4,\n",
    "        name=name,\n",
    "        project=\"example_data_quality/train\"\n",
    "    )\n",
    "    \n",
    "    map_results = test_yolo(\n",
    "        img=608,\n",
    "        data=\"dataset/data.yaml\",\n",
    "        weights=f\"example_data_quality/train/{name}/weights/best.pt\",\n",
    "        project=\"example_data_quality/test\"\n",
    "    )\n",
    "    \n",
    "    return float(map_results.results_dict[\"metrics/mAP50(B)\"])\n",
    "\n",
    "#---------- Original Annotations ----------\n",
    "\n",
    "# Preparing the dataset with the original annotaions\n",
    "split_dataset(train_split=train_split, val_split=val_split, dataset=\"original\") \n",
    "# Train and test the model with original annotations\n",
    "map_original = train_and_test_yolo(\"original\")\n",
    "\n",
    "#---------- Improved Annotations ----------\n",
    "\n",
    "# Preparing the dataset with the improved annotaions\n",
    "split_dataset(train_split=train_split, val_split=val_split, dataset=\"improved\") # Preparing the dataset with the improved annotaions\n",
    "# Train and test the model with improved annotations\n",
    "map_improved = train_and_test_yolo(\"improved\") # Train and test the model with improved annotations\n",
    "\n",
    "#--------- Calculate improvement ---------\n",
    "\n",
    "# Calculate the absolute and relative improvement in mAP\n",
    "improvement = map_improved - map_original\n",
    "# Calculate the percentage improvement\n",
    "percent_improvement = (improvement / map_original) * 100 if map_original > 0 else float('inf')  # Avoid division by zero\n",
    "# Clear training outputs\n",
    "clear_output(wait=True)\n",
    "# Display the results in a Markdown format\n",
    "display(Markdown(f\"\"\"\n",
    "---\n",
    "### **Annotation Quality Comparison**\n",
    "\n",
    "- <span style=\"color:crimson\"><b>mAP with original annotations:</b></span> <code>{map_original:.4f}</code>\n",
    "- <span style=\"color:seagreen\"><b>mAP with improved annotations:</b></span> <code>{map_improved:.4f}</code>\n",
    "\n",
    "**Absolute improvement:** <b style=\"color:royalblue\">{improvement:.4f} mAP@50</b>  \n",
    "**Relative improvement:** <b style=\"color:royalblue\">{percent_improvement:.2f}%</b>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e37783",
   "metadata": {},
   "source": [
    "## üß† Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d691bca",
   "metadata": {},
   "source": [
    "Training object detection models from scratch can be time-consuming and data-hungry. To overcome this, we use **Transfer Learning (TL)** ‚Äî a technique that leverages a model pre-trained on a large dataset (e.g., COCO) and adapts it to our custom task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca0af0",
   "metadata": {},
   "source": [
    "#### What Can Change?\n",
    "\n",
    "- The model‚Äôs **detection head** (final layers) is updated to match the number of classes in our current dataset.\n",
    "- During training, the model retains the **general visual features** it has already learned (e.g., shapes, textures), while adapting to our specific setting.\n",
    "\n",
    "> Transfer Learning helps us build accurate models faster, even with relatively small datasets ‚Äî by reusing knowledge from related tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce52a4d",
   "metadata": {},
   "source": [
    "\n",
    "#### Why Use Transfer Learning?\n",
    "\n",
    "- **Jump-start training** with already-learned features\n",
    "- **Reduce training time**\n",
    "- **Improve performance**, especially when labeled data is limited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d28ebcd",
   "metadata": {},
   "source": [
    "### Reusing a YOLOv5 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669ad421",
   "metadata": {},
   "source": [
    "#### Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeed2f7",
   "metadata": {},
   "source": [
    "In this tutorial, we leverage **Transfer Learning** by starting from a pre-trained **YOLOv5** model trained to detect **whiteflies in yellow sticky traps**:\n",
    "\n",
    "`pre-trained/yellow_trap.pt`\n",
    "\n",
    "Although the original model was trained on the **same task** (whitefly detection), it was collected in a **different environment**. This makes it an excellent candidate for fine-tuning on our custom data.\n",
    "\n",
    "##### YOLOv5 pre-trained on:\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/tl_v5.png)\n",
    "\n",
    "##### New Dataset\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/tl_new.png)\n",
    "\n",
    "As seen in the images above, both scenarios contain **whiteflies**, but in different environments.  \n",
    "A model trained on one of these image sets can be used as a **starting point** for training on the other, leveraging the benefits of **transfer learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740e666",
   "metadata": {},
   "source": [
    "> Recent YOLO models (version 8 and above) are available through the **Ultralytics Python library**.  \n",
    "> However, in this tutorial, we use a **pre-trained YOLOv5 model**, which is **not included** in the `ultralytics` package.\n",
    "\n",
    "> Therefore, we need to **clone the YOLOv5 repository manually** to access its training and inference utilities.\n",
    "\n",
    "> **Note:** The YOLOv5 repository is no longer actively maintained and may produce several warnings during training due to updates in related packages.  \n",
    "> Despite this, it remains **fully functional** and suitable for our fine-tuning task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a43a4ed",
   "metadata": {},
   "source": [
    "#### Cloning YOLOv5 github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f96458",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f374e",
   "metadata": {},
   "source": [
    "#### Experience Preparation\n",
    "\n",
    "In this transfer learning experiment, we train **two distinct models** for comparison:\n",
    "\n",
    "- **Model A:** Starts training using the weights of a **pre-trained YOLOv5** model  \n",
    "- **Model B:** Trains **from scratch** using **YOLOv11n**, with no prior learning\n",
    "\n",
    "Both models are trained using the **same dataset**, including:\n",
    "\n",
    "- Identical **training and validation splits**\n",
    "- Same **number of epochs**, **image size**, and **batch size**\n",
    "\n",
    "---\n",
    "\n",
    "At the end of training, a plot is displayed showing the **evolution of performance (mAP@50)** across epochs for both models, allowing us to visualize and compare their learning behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac4180ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_split, split_dataset, train_yolo, train_yolov5\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get train/val split from dataset (test already fixed 20%)\n",
    "train_split, val_split = get_split(\n",
    "    train_size=0.6, # 60 percent of the dataset for training\n",
    "    val_size=0.2, # 20 percent of the dataset for validation\n",
    "    dataset_size=200\n",
    ")\n",
    "\n",
    "# Images to be used for training and validation will be available in dataset/run\n",
    "split_dataset(train_split=train_split, val_split=val_split, dataset=\"improved\")\n",
    "\n",
    "num_epochs = 5 # Number of epochs for training\n",
    "batch_size = 4 # Batch size for training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325500af",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc7b96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully. Results saved in 'example_transfer_learning/train/transfer_learning' and 'example_transfer_learning/train/baseline'.\n"
     ]
    }
   ],
   "source": [
    "# Train YOLOv5 with transfer learning using pre-trained weights\n",
    "train_yolov5(\n",
    "    img=1280, # pre-trained/yellow_trap.pt was trained on 1280x1280 images, so we use the same size\n",
    "    epochs=num_epochs,\n",
    "    data=\"dataset/data_yolov5.yaml\",\n",
    "    weights=\"pre-trained/yellow_trap.pt\",  # Using YOLOv5 small as the pre-trained model\n",
    "    batch=batch_size,\n",
    "    name=\"transfer_learning\",\n",
    "    project=\"example_transfer_learning\"\n",
    ")\n",
    "\n",
    "# Train YOLOv11 from scratch on the same dataset\n",
    "train_yolo(\n",
    "    img=1280,\n",
    "    epochs=num_epochs,\n",
    "    data=\"dataset/data.yaml\",\n",
    "    weights=\"yolo11n.yaml\",\n",
    "    batch=batch_size,\n",
    "    name=\"baseline\",\n",
    "    project=\"example_transfer_learning/train\"\n",
    ")\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"Training completed successfully. Results saved in 'example_transfer_learning/train/transfer_learning' and 'example_transfer_learning/train/baseline'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e298b1",
   "metadata": {},
   "source": [
    "#### Plot Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd207f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"example_transfer_learning/train/transfer_learning/results.csv\")\n",
    "df2 = pd.read_csv(\"example_transfer_learning/train/baseline/results.csv\")\n",
    "\n",
    "# Strip leading/trailing whitespace from column names\n",
    "df1.columns = df1.columns.str.strip()\n",
    "df2.columns = df2.columns.str.strip()\n",
    "\n",
    "%matplotlib inline\n",
    "# Plotting mAP@0.5\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df1['metrics/mAP_0.5'], label='Transfer Learning', marker='o')\n",
    "plt.plot(df2['metrics/mAP50(B)'], label='Baseline', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('mAP@0.5')\n",
    "plt.title('Comparison of mAP@0.5 Across Experiments')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
