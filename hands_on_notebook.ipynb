{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e01772",
   "metadata": {},
   "source": [
    "# 📘 IbPRIA 2025 - Data-Efficient Strategies for Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c69f66",
   "metadata": {},
   "source": [
    "> 📌 **Note**: You can run this notebook on:\n",
    ">\n",
    "> - 💻 Your local machine (Python ≥ 3.8, see `requirements.txt`)\n",
    "> - 🌐 [Google Colab](https://colab.research.google.com/github/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/blob/main/hands_on_notebook.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec05742",
   "metadata": {},
   "source": [
    "## ⚙️ Preparation to Run This Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16179b25",
   "metadata": {},
   "source": [
    "To ensure faster training and better performance, it is recommended to use a **GPU** when running this notebook.\n",
    "\n",
    "If you're using **Google Colab**, make sure the runtime is configured to use a **GPU** or **TPU**.\n",
    "\n",
    "> 📌 You can change the runtime by going to:  \n",
    "> `Runtime` → `Change runtime type` → Select **GPU** or **TPU**\n",
    "\n",
    "⬇️ See the image below for guidance.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** You can also run this notebook **locally** using your own machine with **CPU only**.  \n",
    "Training may be slower, but all code will still work correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a228b69",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/colab_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b17048",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/colab_2_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "861d6a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10325.71s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (8.3.160)\n",
      "Requirement already satisfied: labelimg in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.8.6)\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (0.13.2)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (3.9.4)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (2.3.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (2.0.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in ./.venv/lib/python3.9/site-packages (from ultralytics->-r requirements.txt (line 1)) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./.venv/lib/python3.9/site-packages (from ultralytics->-r requirements.txt (line 1)) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./.venv/lib/python3.9/site-packages (from ultralytics->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in ./.venv/lib/python3.9/site-packages (from ultralytics->-r requirements.txt (line 1)) (2.32.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./.venv/lib/python3.9/site-packages (from ultralytics->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in ./.venv/lib/python3.9/site-packages (from ultralytics->-r requirements.txt (line 1)) (2.7.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in ./.venv/lib/python3.9/site-packages (from ultralytics->-r requirements.txt (line 1)) (0.22.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in ./.venv/lib/python3.9/site-packages (from ultralytics->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.9/site-packages (from ultralytics->-r requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in ./.venv/lib/python3.9/site-packages (from ultralytics->-r requirements.txt (line 1)) (9.0.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in ./.venv/lib/python3.9/site-packages (from ultralytics->-r requirements.txt (line 1)) (2.0.14)\n",
      "Requirement already satisfied: pyqt5 in ./.venv/lib/python3.9/site-packages (from labelimg->-r requirements.txt (line 2)) (5.15.11)\n",
      "Requirement already satisfied: lxml in ./.venv/lib/python3.9/site-packages (from labelimg->-r requirements.txt (line 2)) (5.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (6.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->-r requirements.txt (line 4)) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 1)) (2025.6.15)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics->-r requirements.txt (line 1)) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics->-r requirements.txt (line 1)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics->-r requirements.txt (line 1)) (2025.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.9/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from jinja2->torch>=1.8.0->ultralytics->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.15 in ./.venv/lib/python3.9/site-packages (from pyqt5->labelimg->-r requirements.txt (line 2)) (12.17.0)\n",
      "Requirement already satisfied: PyQt5-Qt5<5.16.0,>=5.15.2 in ./.venv/lib/python3.9/site-packages (from pyqt5->labelimg->-r requirements.txt (line 2)) (5.15.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if \"COLAB_RELEASE_TAG\" in os.environ:\n",
    "    print(\"✅ Running on Google Colab\")\n",
    "    # Clone the repository if running in Google Colab\n",
    "    !git clone https://github.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection.git\n",
    "    # Change working directory\n",
    "    os.chdir(\"IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection\")\n",
    "\n",
    "%pip install -r requirements.txt # Install required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a6e2c1",
   "metadata": {},
   "source": [
    "## ✏️ Annotation Guidelines for Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35bf29d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In object detection tasks, each image must be labeled with **bounding boxes** that enclose every object the model is expected to detect. For each bounding box, a corresponding **class label** must be assigned.\n",
    "\n",
    "There are several tools available for this annotation process:\n",
    "\n",
    "- If you're working with a **small dataset** and need a lightweight solution, we recommend [labelImg](https://pypi.org/project/labelImg/).\n",
    "- For **larger projects** with multiple annotators, we suggest using a more robust platform such as [Label Studio](https://labelstud.io/), which provide better support for collaboration.\n",
    "\n",
    "### Bounding Box Best Practices\n",
    "\n",
    "A bounding box is defined by its **center coordinates**, **width**, and **height**. For accurate annotations:\n",
    "\n",
    "- The **center of the bounding box** should align with the center of the corresponding object.\n",
    "- The edges of the bounding box should **not exceed the boundaries** of the object.\n",
    "- Boxes should be **tight** but not overly precise — enough to capture the object clearly without including background noise.\n",
    "\n",
    "> Ensuring consistent and accurate annotation is crucial, as it directly impacts the performance and reliability of the trained object detection model.\n",
    "\n",
    "### Running LabelImg Locally\n",
    "\n",
    "If you're running this notebook or working locally (not on Colab), you can install and launch **LabelImg** using the commands below:\n",
    "\n",
    "```bash\n",
    "pip install labelImg\n",
    "```\n",
    "**Important:** LabelImg works best with Python 3.9 or lower. Newer versions may cause compatibility issues. We recommend using a virtual environment with Python 3.9 if needed.\n",
    "\n",
    "To lauch the tool:\n",
    "```bash\n",
    "labelImg\n",
    "```\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/labelimg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a4ad7",
   "metadata": {},
   "source": [
    "## 📏 Evaluation Metrics for Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69485dea",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Evaluating an object detection model involves multiple metrics that assess **localization accuracy**, **classification quality**, and **overall detection performance**. Below are the main metrics and how they apply to our use case:\n",
    "\n",
    "\n",
    "### Intersection over Union (IoU)\n",
    "\n",
    "**IoU** measures the overlap between the predicted bounding box and the ground truth box:\n",
    "\n",
    "$\\text{IoU} = \\frac{\\text{Area of Overlap}}{\\text{Area of Union}}$\n",
    "\n",
    "A prediction is considered a **True Positive (TP)** if its IoU with a ground truth box is above a defined threshold $ \\tau $. Otherwise, it’s a **False Positive (FP)**.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/iou.png)\n",
    "\n",
    "\n",
    "\n",
    "### Confusion Matrix\n",
    "\n",
    "A confusion matrix summarizes the **classification performance** by showing how often each class is correctly or incorrectly predicted:\n",
    "\n",
    "- **TP**: Correctly detected objects  \n",
    "- **FP**: Incorrect predictions  \n",
    "- **FN**: Missed detections  \n",
    "\n",
    "In object detection, this matrix is typically based on **IoU-matched predictions**.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/confusion_matrix.png)\n",
    "\n",
    "\n",
    "### Precision & Recall\n",
    "\n",
    "These metrics quantify how accurate and complete the model’s predictions are:\n",
    "\n",
    "- **Precision** = TP / (TP + FP)  \n",
    "- **Recall** = TP / (TP + FN)\n",
    "\n",
    "\n",
    "\n",
    "### Average Precision (AP) and mAP\n",
    "\n",
    "**Average Precision (AP)** is computed as the area under the Precision–Recall curve, computed by evaluating precision and recall across multiple confidence thresholds at a fixed IoU.  \n",
    "**Mean Average Precision (mAP)** is the mean of APs across all classes or IoU thresholds.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/pr_curve.png)\n",
    "\n",
    "In the example above:\n",
    "- The class `WF` (Whitefly) achieves **0.931 mAP@0.5**, indicating excellent detection performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f7c5bb",
   "metadata": {},
   "source": [
    "## 📂 Dataset Format for YOLO Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1825ff24",
   "metadata": {},
   "source": [
    "\n",
    "To train a YOLO model, your dataset must follow a specific structure and include a `.yaml` configuration file that defines where your images and annotations are located, along with the list of classes.\n",
    "\n",
    "---\n",
    "\n",
    "### Folder Structure\n",
    "\n",
    "Each image should have a corresponding `.txt` annotation file with the same name (e.g., `image1.jpg` ↔ `image1.txt`), and these should be placed in the appropriate subfolders.\n",
    "\n",
    "```text\n",
    "dataset/\n",
    "├── train/\n",
    "├── val/\n",
    "├── test/\n",
    "└── data.yaml\n",
    "```\n",
    "\n",
    "> **Note:** YOLO expects labels in `.txt` format where each line corresponds to one bounding box, with the format:\n",
    ">\n",
    "> ```\n",
    "> <class_id> <x_center> <y_center> <width> <height>\n",
    "> ```\n",
    "> All values must be normalized (from 0 to 1) relative to image size.\n",
    "\n",
    "---\n",
    "\n",
    "### `data.yaml` Example\n",
    "\n",
    "```yaml\n",
    "train: dataset/train/images\n",
    "val: dataset/val/images\n",
    "test: dataset/test/images\n",
    "\n",
    "nc: 1  # number of classes\n",
    "names: ['WF'] #name of the class that MUST match the <class_id> in the annotation file\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b2cbe9",
   "metadata": {},
   "source": [
    "## 👁️ Object Detection with YOLOv11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdd2334",
   "metadata": {},
   "source": [
    "\n",
    "Once your dataset is prepared and organized correctly, you can begin training your YOLOv11 model. In this example, we’ll use the **nano version** of YOLOv11 (`yolov11n.pt`) and train on a custom dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69141f9a",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1: Dataset Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32724b41",
   "metadata": {},
   "source": [
    "We use a utility function to split the dataset into **training** and **validation** sets, assuming a separate **test set** already exists.\n",
    "\n",
    "This example splits a dataset of 200 images into:\n",
    "- **60% for training**\n",
    "- **20% for validation**\n",
    "- The remaining **20% are reserved as the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e9ad0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and validation splits saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from utils import get_split, split_dataset\n",
    "\n",
    "# Get train/val split from dataset (test already fixed)\n",
    "train, val = get_split(train_size=0.6, val_size=0.2, dataset_size=200)\n",
    "\n",
    "# Save to dataset/run/train and dataset/run/val\n",
    "split_dataset(train_split=train, val_split=val)\n",
    "print(\"Train and validation splits saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19989df4",
   "metadata": {},
   "source": [
    "### Step 2: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8507b8",
   "metadata": {},
   "source": [
    "After the dataset splitting process, it is important to define the training parameters.\n",
    "\n",
    "Some important parameters to define are: **image size**, number of **epochs**, how to initialize the model **weights**, and the **batch size**.\n",
    "\n",
    "Let us clarify each of them:\n",
    "\n",
    "**Image size** refers to the resolution to which every input image is resized before being fed into the yolov11 model. This fixed-size input is necessary because the model architecture (fully convolutional with final dense layers) expects inputs of the same size.\n",
    "\n",
    "An **epoch** is one complete pass through the entire training dataset by the learning algorithm.\n",
    "\n",
    "Pre-trained **weights** are obtained by training a model on a large dataset before applying it to a specific task. This approach leverages **transfer learning**, allowing the model to take advantage of already learned general features such as edges, textures, or shapes. We will further explore **transfer learning** and its advantages.\n",
    "\n",
    "Finally, **batch size** is the number of training samples processed before the model updates its weights.\n",
    "\n",
    "For each batch:\n",
    "- The model makes predictions.\n",
    "- The loss is computed.\n",
    "- The optimizer adjusts weights using gradients from that batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a6a8607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.160 🚀 Python-3.9.6 torch-2.7.1 CPU (Apple M3 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov11n_custom, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=example_simple_detector, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=example_simple_detector/yolov11n_custom, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 8755.7±1148.1 MB/s, size: 838.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/dataset/run/train... 120 images, 0 backgrounds, 0 corrupt: 100%|██████████| 120/120 [00:00<00:00, 1298.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/dataset/run/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 7902.8±1068.0 MB/s, size: 748.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/dataset/run/val... 40 images, 0 backgrounds, 0 corrupt: 100%|██████████| 40/40 [00:00<00:00, 2066.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/dataset/run/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to example_simple_detector/yolov11n_custom/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mexample_simple_detector/yolov11n_custom\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      2.166      3.361      1.042        221       1280: 100%|██████████| 30/30 [01:53<00:00,  3.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:12<00:00,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       1932     0.0113     0.0704    0.00987    0.00175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.779      1.992     0.9148        100       1280: 100%|██████████| 30/30 [01:49<00:00,  3.65s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:16<00:00,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       1932     0.0588      0.365      0.231     0.0874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G       1.83       1.89     0.9192        101       1280: 100%|██████████| 30/30 [01:47<00:00,  3.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|██        | 1/5 [00:04<00:18,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|████      | 2/5 [00:09<00:14,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|██████    | 3/5 [00:14<00:10,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|████████  | 4/5 [00:19<00:04,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:24<00:00,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       1932      0.506      0.537      0.472      0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      1.858       1.78     0.9515        138       1280: 100%|██████████| 30/30 [01:44<00:00,  3.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|██        | 1/5 [00:04<00:18,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|████      | 2/5 [00:09<00:14,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|██████    | 3/5 [00:14<00:10,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|████████  | 4/5 [00:19<00:04,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:24<00:00,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       1932      0.639       0.46      0.503       0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      1.774      1.711     0.9285        232       1280: 100%|██████████| 30/30 [01:50<00:00,  3.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|██        | 1/5 [00:04<00:18,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|████      | 2/5 [00:09<00:13,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|████████  | 4/5 [00:18<00:04,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:22<00:00,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       1932      0.694      0.633       0.69      0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      1.637      1.608     0.9065        123       1280: 100%|██████████| 30/30 [01:52<00:00,  3.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|██        | 1/5 [00:04<00:17,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|████      | 2/5 [00:09<00:13,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:22<00:00,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       1932      0.717      0.672      0.734      0.397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G      1.572      1.482     0.8979        228       1280: 100%|██████████| 30/30 [01:43<00:00,  3.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:19<00:00,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       1932      0.742      0.709      0.782       0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G      1.534      1.416     0.8966        116       1280: 100%|██████████| 30/30 [01:42<00:00,  3.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:18<00:00,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       1932      0.768       0.73      0.805      0.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G      1.523      1.401     0.8807        214       1280: 100%|██████████| 30/30 [01:42<00:00,  3.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:17<00:00,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       1932      0.779      0.744      0.822      0.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G      1.448      1.291     0.8887        618       1280: 100%|██████████| 30/30 [01:47<00:00,  3.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:16<00:00,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       1932      0.798      0.738      0.826      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.353 hours.\n",
      "Optimizer stripped from example_simple_detector/yolov11n_custom/weights/last.pt, 5.6MB\n",
      "Optimizer stripped from example_simple_detector/yolov11n_custom/weights/best.pt, 5.6MB\n",
      "\n",
      "Validating example_simple_detector/yolov11n_custom/weights/best.pt...\n",
      "Ultralytics 8.3.160 🚀 Python-3.9.6 torch-2.7.1 CPU (Apple M3 Pro)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:15<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40       1932      0.797      0.739      0.826      0.504\n",
      "Speed: 3.8ms preprocess, 166.4ms inference, 0.0ms loss, 153.7ms postprocess per image\n",
      "Results saved to \u001b[1mexample_simple_detector/yolov11n_custom\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from utils import train_yolo\n",
    "\n",
    "project = \"example_simple_detector\" # Project directory for saving results\n",
    "\n",
    "name = \"yolov11n_custom\"\n",
    "\n",
    "image_size = 1280 # Image size for training\n",
    "epochs = 10 # Number of epochs for training\n",
    "batch_size = 4 # Batch size for training\n",
    "\n",
    "# Train the YOLO model\n",
    "trained = train_yolo(\n",
    "    img=image_size, # Image size\n",
    "    epochs=epochs, # Number of epochs\n",
    "    data=\"dataset/data.yaml\", # Path to data configuration file\n",
    "    weights=\"yolo11n.pt\", # Pre-trained weights from COCO dataset\n",
    "    batch=batch_size, # Batch size\n",
    "    name=name, # Name of the training run\n",
    "    project=project # Project directory for saving results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b4ab55",
   "metadata": {},
   "source": [
    "### Step 3: Detection with the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9221309",
   "metadata": {},
   "source": [
    "Once your model has been trained, you can use it to detect objects in new images.\n",
    "\n",
    "Below is an example of how to **load your trained YOLOv11 model**, run inference on a single image, and **visualize the results** using `OpenCV` and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b017991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 16 Whiteflys, 118.8ms\n",
      "video 1/1 (frame 2/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 15 Whiteflys, 120.0ms\n",
      "video 1/1 (frame 3/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 101.6ms\n",
      "video 1/1 (frame 4/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 16 Whiteflys, 93.7ms\n",
      "video 1/1 (frame 5/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 101.6ms\n",
      "video 1/1 (frame 6/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 104.1ms\n",
      "video 1/1 (frame 7/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 95.7ms\n",
      "video 1/1 (frame 8/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 106.9ms\n",
      "video 1/1 (frame 9/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 100.4ms\n",
      "video 1/1 (frame 10/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 93.9ms\n",
      "video 1/1 (frame 11/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 103.5ms\n",
      "video 1/1 (frame 12/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 98.6ms\n",
      "video 1/1 (frame 13/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 96.3ms\n",
      "video 1/1 (frame 14/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 99.6ms\n",
      "video 1/1 (frame 15/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 98.5ms\n",
      "video 1/1 (frame 16/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 98.3ms\n",
      "video 1/1 (frame 17/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 93.0ms\n",
      "video 1/1 (frame 18/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 92.5ms\n",
      "video 1/1 (frame 19/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 104.4ms\n",
      "video 1/1 (frame 20/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 95.8ms\n",
      "video 1/1 (frame 21/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 97.0ms\n",
      "video 1/1 (frame 22/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 94.6ms\n",
      "video 1/1 (frame 23/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 98.4ms\n",
      "video 1/1 (frame 24/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 93.7ms\n",
      "video 1/1 (frame 25/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 99.4ms\n",
      "video 1/1 (frame 26/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 102.4ms\n",
      "video 1/1 (frame 27/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 101.8ms\n",
      "video 1/1 (frame 28/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 96.6ms\n",
      "video 1/1 (frame 29/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 97.0ms\n",
      "video 1/1 (frame 30/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 98.2ms\n",
      "video 1/1 (frame 31/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 102.8ms\n",
      "video 1/1 (frame 32/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 98.3ms\n",
      "video 1/1 (frame 33/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 93.3ms\n",
      "video 1/1 (frame 34/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 105.0ms\n",
      "video 1/1 (frame 35/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 100.9ms\n",
      "video 1/1 (frame 36/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 92.8ms\n",
      "video 1/1 (frame 37/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 97.2ms\n",
      "video 1/1 (frame 38/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 95.2ms\n",
      "video 1/1 (frame 39/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 94.3ms\n",
      "video 1/1 (frame 40/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 95.2ms\n",
      "video 1/1 (frame 41/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 104.7ms\n",
      "video 1/1 (frame 42/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 107.1ms\n",
      "video 1/1 (frame 43/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 120.9ms\n",
      "video 1/1 (frame 44/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 95.4ms\n",
      "video 1/1 (frame 45/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 95.2ms\n",
      "video 1/1 (frame 46/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 101.2ms\n",
      "video 1/1 (frame 47/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 97.8ms\n",
      "video 1/1 (frame 48/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 99.8ms\n",
      "video 1/1 (frame 49/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 101.2ms\n",
      "video 1/1 (frame 50/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 114.0ms\n",
      "video 1/1 (frame 51/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 94.2ms\n",
      "video 1/1 (frame 52/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 101.9ms\n",
      "video 1/1 (frame 53/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 102.3ms\n",
      "video 1/1 (frame 54/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 96.4ms\n",
      "video 1/1 (frame 55/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 96.1ms\n",
      "video 1/1 (frame 56/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 96.4ms\n",
      "video 1/1 (frame 57/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 100.3ms\n",
      "video 1/1 (frame 58/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 93.7ms\n",
      "video 1/1 (frame 59/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 97.3ms\n",
      "video 1/1 (frame 60/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 95.9ms\n",
      "video 1/1 (frame 61/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 93.2ms\n",
      "video 1/1 (frame 62/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 101.2ms\n",
      "video 1/1 (frame 63/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 97.1ms\n",
      "video 1/1 (frame 64/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 97.3ms\n",
      "video 1/1 (frame 65/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 93.7ms\n",
      "video 1/1 (frame 66/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 94.1ms\n",
      "video 1/1 (frame 67/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 94.4ms\n",
      "video 1/1 (frame 68/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 99.8ms\n",
      "video 1/1 (frame 69/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 94.1ms\n",
      "video 1/1 (frame 70/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 93.8ms\n",
      "video 1/1 (frame 71/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 95.4ms\n",
      "video 1/1 (frame 72/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 130.7ms\n",
      "video 1/1 (frame 73/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 99.5ms\n",
      "video 1/1 (frame 74/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 94.2ms\n",
      "video 1/1 (frame 75/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 94.4ms\n",
      "video 1/1 (frame 76/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 97.4ms\n",
      "video 1/1 (frame 77/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 99.2ms\n",
      "video 1/1 (frame 78/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 94.7ms\n",
      "video 1/1 (frame 79/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 103.8ms\n",
      "video 1/1 (frame 80/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 97.9ms\n",
      "video 1/1 (frame 81/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 98.7ms\n",
      "video 1/1 (frame 82/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 96.0ms\n",
      "video 1/1 (frame 83/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 107.1ms\n",
      "video 1/1 (frame 84/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 102.1ms\n",
      "video 1/1 (frame 85/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 94.5ms\n",
      "video 1/1 (frame 86/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 15 Whiteflys, 96.5ms\n",
      "video 1/1 (frame 87/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 15 Whiteflys, 94.6ms\n",
      "video 1/1 (frame 88/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 96.2ms\n",
      "video 1/1 (frame 89/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 15 Whiteflys, 98.6ms\n",
      "video 1/1 (frame 90/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 92.1ms\n",
      "video 1/1 (frame 91/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 95.3ms\n",
      "video 1/1 (frame 92/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 15 Whiteflys, 98.3ms\n",
      "video 1/1 (frame 93/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 12 Whiteflys, 98.5ms\n",
      "video 1/1 (frame 94/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 14 Whiteflys, 100.1ms\n",
      "video 1/1 (frame 95/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 96.5ms\n",
      "video 1/1 (frame 96/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 98.5ms\n",
      "video 1/1 (frame 97/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 100.2ms\n",
      "video 1/1 (frame 98/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 96.7ms\n",
      "video 1/1 (frame 99/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 98.3ms\n",
      "video 1/1 (frame 100/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 100.8ms\n",
      "video 1/1 (frame 101/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 96.0ms\n",
      "video 1/1 (frame 102/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 96.1ms\n",
      "video 1/1 (frame 103/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 103.3ms\n",
      "video 1/1 (frame 104/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 97.1ms\n",
      "video 1/1 (frame 105/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 95.6ms\n",
      "video 1/1 (frame 106/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 96.9ms\n",
      "video 1/1 (frame 107/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 95.5ms\n",
      "video 1/1 (frame 108/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 97.1ms\n",
      "video 1/1 (frame 109/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 99.4ms\n",
      "video 1/1 (frame 110/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 100.4ms\n",
      "video 1/1 (frame 111/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 96.3ms\n",
      "video 1/1 (frame 112/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 98.6ms\n",
      "video 1/1 (frame 113/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 96.8ms\n",
      "video 1/1 (frame 114/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 97.1ms\n",
      "video 1/1 (frame 115/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 93.6ms\n",
      "video 1/1 (frame 116/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 94.5ms\n",
      "video 1/1 (frame 117/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 100.4ms\n",
      "video 1/1 (frame 118/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 101.9ms\n",
      "video 1/1 (frame 119/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 95.2ms\n",
      "video 1/1 (frame 120/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 95.8ms\n",
      "video 1/1 (frame 121/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 95.3ms\n",
      "video 1/1 (frame 122/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 95.1ms\n",
      "video 1/1 (frame 123/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 94.3ms\n",
      "video 1/1 (frame 124/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 97.5ms\n",
      "video 1/1 (frame 125/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 96.3ms\n",
      "video 1/1 (frame 126/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 94.9ms\n",
      "video 1/1 (frame 127/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 96.3ms\n",
      "video 1/1 (frame 128/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 95.9ms\n",
      "video 1/1 (frame 129/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 98.0ms\n",
      "video 1/1 (frame 130/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 98.3ms\n",
      "video 1/1 (frame 131/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 4 Whiteflys, 96.9ms\n",
      "video 1/1 (frame 132/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 96.2ms\n",
      "video 1/1 (frame 133/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 96.1ms\n",
      "video 1/1 (frame 134/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 91.7ms\n",
      "video 1/1 (frame 135/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 4 Whiteflys, 92.7ms\n",
      "video 1/1 (frame 136/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 98.0ms\n",
      "video 1/1 (frame 137/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 100.5ms\n",
      "video 1/1 (frame 138/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 99.2ms\n",
      "video 1/1 (frame 139/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 95.0ms\n",
      "video 1/1 (frame 140/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 95.5ms\n",
      "video 1/1 (frame 141/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 99.8ms\n",
      "video 1/1 (frame 142/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 103.5ms\n",
      "video 1/1 (frame 143/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 99.1ms\n",
      "video 1/1 (frame 144/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 100.4ms\n",
      "video 1/1 (frame 145/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 96.2ms\n",
      "video 1/1 (frame 146/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 97.4ms\n",
      "video 1/1 (frame 147/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 98.4ms\n",
      "video 1/1 (frame 148/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 97.1ms\n",
      "video 1/1 (frame 149/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 97.7ms\n",
      "video 1/1 (frame 150/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 97.9ms\n",
      "video 1/1 (frame 151/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 97.2ms\n",
      "video 1/1 (frame 152/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 98.7ms\n",
      "video 1/1 (frame 153/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 100.7ms\n",
      "video 1/1 (frame 154/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 110.7ms\n",
      "video 1/1 (frame 155/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 120.7ms\n",
      "video 1/1 (frame 156/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 111.1ms\n",
      "video 1/1 (frame 157/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 98.9ms\n",
      "video 1/1 (frame 158/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 13 Whiteflys, 105.8ms\n",
      "video 1/1 (frame 159/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 123.8ms\n",
      "video 1/1 (frame 160/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 106.6ms\n",
      "video 1/1 (frame 161/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 110.7ms\n",
      "video 1/1 (frame 162/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 98.9ms\n",
      "video 1/1 (frame 163/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 98.1ms\n",
      "video 1/1 (frame 164/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 171.0ms\n",
      "video 1/1 (frame 165/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 117.6ms\n",
      "video 1/1 (frame 166/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 107.0ms\n",
      "video 1/1 (frame 167/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 101.2ms\n",
      "video 1/1 (frame 168/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 101.5ms\n",
      "video 1/1 (frame 169/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 100.8ms\n",
      "video 1/1 (frame 170/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 103.3ms\n",
      "video 1/1 (frame 171/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 104.7ms\n",
      "video 1/1 (frame 172/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 99.4ms\n",
      "video 1/1 (frame 173/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 100.0ms\n",
      "video 1/1 (frame 174/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 114.9ms\n",
      "video 1/1 (frame 175/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 115.5ms\n",
      "video 1/1 (frame 176/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 100.9ms\n",
      "video 1/1 (frame 177/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 104.1ms\n",
      "video 1/1 (frame 178/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 4 Whiteflys, 101.8ms\n",
      "video 1/1 (frame 179/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 129.1ms\n",
      "video 1/1 (frame 180/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 97.3ms\n",
      "video 1/1 (frame 181/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 99.9ms\n",
      "video 1/1 (frame 182/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 101.6ms\n",
      "video 1/1 (frame 183/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 96.3ms\n",
      "video 1/1 (frame 184/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 103.4ms\n",
      "video 1/1 (frame 185/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 95.7ms\n",
      "video 1/1 (frame 186/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 98.5ms\n",
      "video 1/1 (frame 187/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 99.1ms\n",
      "video 1/1 (frame 188/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 99.1ms\n",
      "video 1/1 (frame 189/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 101.6ms\n",
      "video 1/1 (frame 190/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 99.3ms\n",
      "video 1/1 (frame 191/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 103.8ms\n",
      "video 1/1 (frame 192/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 96.7ms\n",
      "video 1/1 (frame 193/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 97.9ms\n",
      "video 1/1 (frame 194/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 101.0ms\n",
      "video 1/1 (frame 195/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 100.9ms\n",
      "video 1/1 (frame 196/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 97.1ms\n",
      "video 1/1 (frame 197/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 103.6ms\n",
      "video 1/1 (frame 198/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 132.0ms\n",
      "video 1/1 (frame 199/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 114.8ms\n",
      "video 1/1 (frame 200/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 105.3ms\n",
      "video 1/1 (frame 201/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 114.7ms\n",
      "video 1/1 (frame 202/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 104.2ms\n",
      "video 1/1 (frame 203/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 100.4ms\n",
      "video 1/1 (frame 204/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 100.9ms\n",
      "video 1/1 (frame 205/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 96.3ms\n",
      "video 1/1 (frame 206/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 97.9ms\n",
      "video 1/1 (frame 207/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 100.1ms\n",
      "video 1/1 (frame 208/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 100.4ms\n",
      "video 1/1 (frame 209/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 96.6ms\n",
      "video 1/1 (frame 210/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 97.2ms\n",
      "video 1/1 (frame 211/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 99.0ms\n",
      "video 1/1 (frame 212/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 97.8ms\n",
      "video 1/1 (frame 213/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 94.3ms\n",
      "video 1/1 (frame 214/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 112.6ms\n",
      "video 1/1 (frame 215/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 115.4ms\n",
      "video 1/1 (frame 216/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 111.8ms\n",
      "video 1/1 (frame 217/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 112.6ms\n",
      "video 1/1 (frame 218/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 122.6ms\n",
      "video 1/1 (frame 219/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 111.4ms\n",
      "video 1/1 (frame 220/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 111.2ms\n",
      "video 1/1 (frame 221/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 107.6ms\n",
      "video 1/1 (frame 222/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 116.4ms\n",
      "video 1/1 (frame 223/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 118.5ms\n",
      "video 1/1 (frame 224/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 117.8ms\n",
      "video 1/1 (frame 225/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 108.3ms\n",
      "video 1/1 (frame 226/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 115.3ms\n",
      "video 1/1 (frame 227/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 112.3ms\n",
      "video 1/1 (frame 228/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 109.8ms\n",
      "video 1/1 (frame 229/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 114.6ms\n",
      "video 1/1 (frame 230/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 112.4ms\n",
      "video 1/1 (frame 231/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 109.8ms\n",
      "video 1/1 (frame 232/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 111.6ms\n",
      "video 1/1 (frame 233/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 113.5ms\n",
      "video 1/1 (frame 234/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 108.8ms\n",
      "video 1/1 (frame 235/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 112.0ms\n",
      "video 1/1 (frame 236/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 115.7ms\n",
      "video 1/1 (frame 237/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 114.4ms\n",
      "video 1/1 (frame 238/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 117.9ms\n",
      "video 1/1 (frame 239/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 111.0ms\n",
      "video 1/1 (frame 240/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 118.0ms\n",
      "video 1/1 (frame 241/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 108.1ms\n",
      "video 1/1 (frame 242/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 109.6ms\n",
      "video 1/1 (frame 243/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 110.0ms\n",
      "video 1/1 (frame 244/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 114.0ms\n",
      "video 1/1 (frame 245/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 113.9ms\n",
      "video 1/1 (frame 246/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 4 Whiteflys, 115.6ms\n",
      "video 1/1 (frame 247/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 117.6ms\n",
      "video 1/1 (frame 248/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 112.7ms\n",
      "video 1/1 (frame 249/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 108.4ms\n",
      "video 1/1 (frame 250/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 115.5ms\n",
      "video 1/1 (frame 251/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 110.6ms\n",
      "video 1/1 (frame 252/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 112.0ms\n",
      "video 1/1 (frame 253/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 104.7ms\n",
      "video 1/1 (frame 254/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 112.5ms\n",
      "video 1/1 (frame 255/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 97.2ms\n",
      "video 1/1 (frame 256/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 93.4ms\n",
      "video 1/1 (frame 257/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 103.5ms\n",
      "video 1/1 (frame 258/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 97.1ms\n",
      "video 1/1 (frame 259/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 94.1ms\n",
      "video 1/1 (frame 260/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 101.4ms\n",
      "video 1/1 (frame 261/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 97.4ms\n",
      "video 1/1 (frame 262/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 94.9ms\n",
      "video 1/1 (frame 263/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 106.6ms\n",
      "video 1/1 (frame 264/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 96.8ms\n",
      "video 1/1 (frame 265/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 98.2ms\n",
      "video 1/1 (frame 266/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 4 Whiteflys, 96.6ms\n",
      "video 1/1 (frame 267/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 109.1ms\n",
      "video 1/1 (frame 268/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 107.6ms\n",
      "video 1/1 (frame 269/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 118.4ms\n",
      "video 1/1 (frame 270/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 4 Whiteflys, 116.6ms\n",
      "video 1/1 (frame 271/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 99.3ms\n",
      "video 1/1 (frame 272/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 110.2ms\n",
      "video 1/1 (frame 273/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 101.3ms\n",
      "video 1/1 (frame 274/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 110.0ms\n",
      "video 1/1 (frame 275/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 4 Whiteflys, 96.8ms\n",
      "video 1/1 (frame 276/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 98.6ms\n",
      "video 1/1 (frame 277/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 97.9ms\n",
      "video 1/1 (frame 278/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 98.0ms\n",
      "video 1/1 (frame 279/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 97.6ms\n",
      "video 1/1 (frame 280/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 97.5ms\n",
      "video 1/1 (frame 281/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 11 Whiteflys, 96.8ms\n",
      "video 1/1 (frame 282/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 98.1ms\n",
      "video 1/1 (frame 283/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 99.5ms\n",
      "video 1/1 (frame 284/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 95.7ms\n",
      "video 1/1 (frame 285/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 95.6ms\n",
      "video 1/1 (frame 286/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 96.8ms\n",
      "video 1/1 (frame 287/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 95.4ms\n",
      "video 1/1 (frame 288/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 99.6ms\n",
      "video 1/1 (frame 289/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 96.7ms\n",
      "video 1/1 (frame 290/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 97.6ms\n",
      "video 1/1 (frame 291/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 95.7ms\n",
      "video 1/1 (frame 292/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 98.0ms\n",
      "video 1/1 (frame 293/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 102.2ms\n",
      "video 1/1 (frame 294/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 106.9ms\n",
      "video 1/1 (frame 295/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 95.4ms\n",
      "video 1/1 (frame 296/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 95.2ms\n",
      "video 1/1 (frame 297/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 97.8ms\n",
      "video 1/1 (frame 298/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 95.9ms\n",
      "video 1/1 (frame 299/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 95.1ms\n",
      "video 1/1 (frame 300/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 95.6ms\n",
      "video 1/1 (frame 301/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 113.2ms\n",
      "video 1/1 (frame 302/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 10 Whiteflys, 98.6ms\n",
      "video 1/1 (frame 303/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 97.1ms\n",
      "video 1/1 (frame 304/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 95.3ms\n",
      "video 1/1 (frame 305/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 96.1ms\n",
      "video 1/1 (frame 306/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 98.8ms\n",
      "video 1/1 (frame 307/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 97.9ms\n",
      "video 1/1 (frame 308/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 98.9ms\n",
      "video 1/1 (frame 309/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 94.4ms\n",
      "video 1/1 (frame 310/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 97.7ms\n",
      "video 1/1 (frame 311/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 4 Whiteflys, 97.9ms\n",
      "video 1/1 (frame 312/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 95.7ms\n",
      "video 1/1 (frame 313/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 95.0ms\n",
      "video 1/1 (frame 314/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 4 Whiteflys, 97.0ms\n",
      "video 1/1 (frame 315/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 97.9ms\n",
      "video 1/1 (frame 316/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 100.4ms\n",
      "video 1/1 (frame 317/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 104.4ms\n",
      "video 1/1 (frame 318/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 4 Whiteflys, 96.5ms\n",
      "video 1/1 (frame 319/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 96.9ms\n",
      "video 1/1 (frame 320/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 101.6ms\n",
      "video 1/1 (frame 321/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 99.0ms\n",
      "video 1/1 (frame 322/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 9 Whiteflys, 95.4ms\n",
      "video 1/1 (frame 323/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 95.1ms\n",
      "video 1/1 (frame 324/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 8 Whiteflys, 97.8ms\n",
      "video 1/1 (frame 325/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 97.7ms\n",
      "video 1/1 (frame 326/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 95.7ms\n",
      "video 1/1 (frame 327/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 7 Whiteflys, 98.2ms\n",
      "video 1/1 (frame 328/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 95.5ms\n",
      "video 1/1 (frame 329/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 4 Whiteflys, 97.5ms\n",
      "video 1/1 (frame 330/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 96.0ms\n",
      "video 1/1 (frame 331/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 96.7ms\n",
      "video 1/1 (frame 332/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 96.8ms\n",
      "video 1/1 (frame 333/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 4 Whiteflys, 95.4ms\n",
      "video 1/1 (frame 334/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 95.2ms\n",
      "video 1/1 (frame 335/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 95.9ms\n",
      "video 1/1 (frame 336/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 99.4ms\n",
      "video 1/1 (frame 337/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 101.3ms\n",
      "video 1/1 (frame 338/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 93.9ms\n",
      "video 1/1 (frame 339/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 97.9ms\n",
      "video 1/1 (frame 340/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 4 Whiteflys, 102.7ms\n",
      "video 1/1 (frame 341/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 95.9ms\n",
      "video 1/1 (frame 342/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 98.7ms\n",
      "video 1/1 (frame 343/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 96.8ms\n",
      "video 1/1 (frame 344/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 4 Whiteflys, 97.9ms\n",
      "video 1/1 (frame 345/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 6 Whiteflys, 98.6ms\n",
      "video 1/1 (frame 346/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 99.6ms\n",
      "video 1/1 (frame 347/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 1 Whitefly, 98.0ms\n",
      "video 1/1 (frame 348/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 1 Whitefly, 101.6ms\n",
      "video 1/1 (frame 349/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 97.1ms\n",
      "video 1/1 (frame 350/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 99.9ms\n",
      "video 1/1 (frame 351/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 95.9ms\n",
      "video 1/1 (frame 352/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 4 Whiteflys, 98.4ms\n",
      "video 1/1 (frame 353/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 98.0ms\n",
      "video 1/1 (frame 354/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 97.6ms\n",
      "video 1/1 (frame 355/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 97.4ms\n",
      "video 1/1 (frame 356/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 1 Whitefly, 98.6ms\n",
      "video 1/1 (frame 357/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 101.9ms\n",
      "video 1/1 (frame 358/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 1 Whitefly, 97.5ms\n",
      "video 1/1 (frame 359/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 1 Whitefly, 96.5ms\n",
      "video 1/1 (frame 360/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 1 Whitefly, 97.3ms\n",
      "video 1/1 (frame 361/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 104.0ms\n",
      "video 1/1 (frame 362/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 100.9ms\n",
      "video 1/1 (frame 363/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 97.5ms\n",
      "video 1/1 (frame 364/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 5 Whiteflys, 99.8ms\n",
      "video 1/1 (frame 365/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 100.1ms\n",
      "video 1/1 (frame 366/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 98.0ms\n",
      "video 1/1 (frame 367/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 99.7ms\n",
      "video 1/1 (frame 368/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 100.1ms\n",
      "video 1/1 (frame 369/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 97.1ms\n",
      "video 1/1 (frame 370/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 100.0ms\n",
      "video 1/1 (frame 371/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 98.3ms\n",
      "video 1/1 (frame 372/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 97.0ms\n",
      "video 1/1 (frame 373/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 97.6ms\n",
      "video 1/1 (frame 374/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 98.2ms\n",
      "video 1/1 (frame 375/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 98.2ms\n",
      "video 1/1 (frame 376/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 175.1ms\n",
      "video 1/1 (frame 377/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 109.7ms\n",
      "video 1/1 (frame 378/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 105.0ms\n",
      "video 1/1 (frame 379/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 103.6ms\n",
      "video 1/1 (frame 380/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 98.8ms\n",
      "video 1/1 (frame 381/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 123.3ms\n",
      "video 1/1 (frame 382/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 (no detections), 98.7ms\n",
      "video 1/1 (frame 383/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 3 Whiteflys, 102.0ms\n",
      "video 1/1 (frame 384/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 1 Whitefly, 96.0ms\n",
      "video 1/1 (frame 385/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 (no detections), 101.6ms\n",
      "video 1/1 (frame 386/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 98.0ms\n",
      "video 1/1 (frame 387/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 2 Whiteflys, 96.3ms\n",
      "video 1/1 (frame 388/388) /Users/ddcosta/Desktop/IbPRIA2015---Data-Efficient-Strategies-for-Object-Detection/examples/example_video.mp4: 736x1280 1 Whitefly, 99.1ms\n",
      "Speed: 3.6ms preprocess, 101.4ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "Results saved to \u001b[1m.temp/detect/detect\u001b[0m\n",
      "386 labels saved to .temp/detect/detect/labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\".temp/detect/detect/example_video.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import detect_yolo\n",
    "import os\n",
    "from IPython.display import Image, Video, display\n",
    "\n",
    "file_to_detect = 'examples/example_video.mp4'  # or use an image like 'dataset/improved/2.jpg'\n",
    "# file_to_detect = 'dataset/improved/2.jpg'\n",
    "\n",
    "# Run detection using the trained YOLO model\n",
    "results = detect_yolo(\n",
    "    source=file_to_detect,\n",
    "    weights=f\"{project}/{name}/weights/best.pt\",\n",
    "    img=image_size,\n",
    ")\n",
    "\n",
    "# Get the output path\n",
    "output_dir = results[0].save_dir  # YOLO typically saves to 'runs/detect/<name>/'\n",
    "file_name = os.path.basename(file_to_detect)\n",
    "output_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "# Display output based on extension\n",
    "if file_to_detect.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "    display(Image(filename=output_path))\n",
    "elif file_to_detect.lower().endswith(('.mp4', '.mov', '.avi')) and \"COLAB_RELEASE_TAG\" not in os.environ: # Avoid displaying video in Colab\n",
    "    display(Video(filename=output_path))\n",
    "else:\n",
    "    print(f\"Unsupported file type: {file_to_detect}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc443367",
   "metadata": {},
   "source": [
    "## 🤖 Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de08a0",
   "metadata": {},
   "source": [
    "The goal of **Active Learning (AL)** is to select the **most relevant samples** to be labeled first and used to train a model.  \n",
    "This approach is particularly useful when **labeling data is expensive or time-consuming**.\n",
    "\n",
    "Even with a **small initial set of labeled data**, it is possible to train a baseline model.  \n",
    "To improve the model further, we need more labeled data — but instead of labeling everything, **Active Learning helps prioritize** which samples to label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea14083",
   "metadata": {},
   "source": [
    "### Active Learning Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10317689",
   "metadata": {},
   "source": [
    "There are two main approaches to Active Learning:\n",
    "\n",
    "#### Stream-Based Selective Sampling\n",
    "\n",
    "- Unlabeled data points are processed **one at a time**.\n",
    "- For each sample, the model must decide **immediately** whether to query its label or discard it.\n",
    "- Useful when data arrives in real time or memory is limited.\n",
    "\n",
    "#### Pool-Based Sampling\n",
    "\n",
    "- The model evaluates a **pool of unlabeled data** all at once.\n",
    "- Each sample is scored based on a **relevance criterion** (e.g., confidence, entropy).\n",
    "- The **top-K most informative** samples are selected and labeled.\n",
    "- This is the most commonly used method in practice.\n",
    "\n",
    "In Pool-based the process works as follows:\n",
    "\n",
    "##### 1. A model is trained on the current labeled dataset.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/al_1.png)\n",
    "\n",
    "##### 2. The model is then used to evaluate the **unlabeled data**.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/al_2.png)\n",
    "\n",
    "##### 3. Based on its predictions, the model **scores all unlabeled samples** using a selection strategy (e.g., uncertainty, disagreement, diversity).\n",
    "   - Samples are then **ranked** by relevance.\n",
    "   - Common scoring strategies include:\n",
    "     - **Uncertainty sampling**: Select samples with the lowest confidence (highest uncertainty).\n",
    "     - **Diversity sampling**: Choose a diverse set of samples to maximize information gain and avoid redundancy.\n",
    "     - **Representativeness**: Pick samples that best represent the distribution of the overall data.\n",
    "     - **Entropy-based sampling**: Select samples with the highest prediction entropy (more confusion between classes).\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/al_3.png)\n",
    "\n",
    "##### 4. Based on the ranking, the **top-K most relevant samples are selected, labeled by an expert, and added to the labeled set**.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/al_4.png)\n",
    "\n",
    "##### 5. This cycle repeats, improving the model efficiently while **minimizing annotation effort**.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/al_5.png)\n",
    "\n",
    "---\n",
    "\n",
    "By focusing labeling efforts on the **most informative samples**, Active Learning enables more efficient training and faster model improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be83b39",
   "metadata": {},
   "source": [
    "### Experiment Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc164d",
   "metadata": {},
   "source": [
    "In this section, we evaluate the impact of **Active Learning (AL)** in a Pool-based scenario by training and comparing **two models**:\n",
    "\n",
    "##### Incremental Training Strategy\n",
    "\n",
    "Both models are trained **incrementally**:\n",
    "\n",
    "- Training begins with a **small subset** of images for training and validation.\n",
    "- At each iteration, a **new batch of data** is added to the training and validation sets.\n",
    "- A new model is trained after each update.\n",
    "- This process is repeated for a fixed number of iterations, defined by the variable `num_batches`.\n",
    "\n",
    "The number of images added in each iteration is determined by:\n",
    "\n",
    "- `batch_train_proportion * dataset_size` for training images\n",
    "- `batch_val_proportion * dataset_size` for validation images\n",
    "\n",
    "---\n",
    "\n",
    "##### Model Variants\n",
    "\n",
    "- **Active Learning Model:**  \n",
    "  Selects new images based on **model uncertainty**, e.g., low confidence in predictions. This ensures the **most informative** samples are used in training in first place.\n",
    "\n",
    "- **Random Selection Model:**  \n",
    "  Selects new images **randomly** from the unlabeled pool at each iteration, serving as a baseline for comparison.\n",
    "\n",
    "---\n",
    "\n",
    "##### ⚙️ Key Parameters\n",
    "\n",
    "- `num_batches`: Number of incremental iterations (rounds of training)\n",
    "- `batch_train_proportion`: Proportion of the dataset used for training in each batch\n",
    "- `batch_val_proportion`: Proportion of the dataset used for validation in each batch\n",
    "\n",
    "These parameters control **how much data is added per iteration** and ensure both models grow in training size at the same pace, allowing for a fair comparison.\n",
    "\n",
    "---\n",
    "\n",
    "📈 At the end of the experiment, we compare the models using their **mAP@50** scores across iterations to evaluate which strategy learns more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c01706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_split, split_dataset, new_batch, train_yolo, test_yolo\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# -------- Dataset setup --------\n",
    "# Define dataset parameters\n",
    "\n",
    "dataset_size = 200 # Total number of images in the dataset\n",
    "num_batches = 8 # Number of batches to process\n",
    "batch_train_prop = 0.6 / num_batches # Proportion of images in each batch for training (60% of the dataset)\n",
    "batch_val_prop = 0.2 / num_batches # Proportion of images in each batch for validation (20% of the dataset)\n",
    "\n",
    "num_epochs = 5 # Number of epochs for each training run\n",
    "batch_size = 4 # Batch size for training\n",
    "image_size = 608 # Image size for detection\n",
    "\n",
    "# Project base\n",
    "project = \"example_active_learning\" # Base project directory for saving results\n",
    "base_weights = \"yolo11n.pt\" # Pre-trained weights to start training from\n",
    "\n",
    "results_df = pd.DataFrame(index=range(num_batches)) # DataFrame to store results\n",
    "\n",
    "# -------- Initial split --------\n",
    "# Get initial train/val split for the first batch \n",
    "# this will ensure both models start with the same initial data\n",
    "initial_train_split, initial_val_split = get_split(\n",
    "                train_size=batch_train_prop,\n",
    "                val_size=batch_val_prop,\n",
    "                dataset_size=dataset_size\n",
    "            ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2575a42c",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1154cdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>al mAP (test)</th>\n",
       "      <th>random mAP (test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011948</td>\n",
       "      <td>0.004751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021350</td>\n",
       "      <td>0.021636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.111487</td>\n",
       "      <td>0.080489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.131083</td>\n",
       "      <td>0.161272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.287208</td>\n",
       "      <td>0.299778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.362823</td>\n",
       "      <td>0.356262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.356412</td>\n",
       "      <td>0.309008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   al mAP (test)  random mAP (test)\n",
       "0       0.000260           0.000260\n",
       "1       0.011948           0.004751\n",
       "2       0.021350           0.021636\n",
       "3       0.111487           0.080489\n",
       "4       0.131083           0.161272\n",
       "5       0.287208           0.299778\n",
       "6       0.362823           0.356262\n",
       "7       0.356412           0.309008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a function to run a full mode (AL or random)\n",
    "def run_training_loop(mode=\"al\"):\n",
    "\n",
    "    for batch in range(num_batches): # Loop through each batch\n",
    "        print(f\"\\n=== Batch {batch} / {num_batches} — Mode: {mode} ===\")\n",
    "        name = f\"{mode}_batch_{batch}\" # Name for the current batch run (directory)\n",
    "\n",
    "        if batch == 0: # First batch, use initial split\n",
    "            split_dataset(train_split=initial_train_split, val_split=initial_val_split)\n",
    "        else: # Subsequent batches, select new data\n",
    "            new_batch(\n",
    "                random=(mode == \"random\"), # Random selection if mode is \"random\"\n",
    "                al=\"confidence\", # Use confidence-based selection for active learning (other opriont: \"count\" - selected images with the most detections)\n",
    "                weights=weights, # Weights from the previous batch\n",
    "                train_images=int(batch_train_prop * dataset_size),\n",
    "                val_images=int(batch_val_prop * dataset_size),\n",
    "                project=f\"{project}_{mode}/detecting\",\n",
    "                name=name,\n",
    "                dataset=\"original\",\n",
    "                img_size=image_size\n",
    "            )\n",
    "        \n",
    "        # Train the YOLO model with the selected data\n",
    "        results = train_yolo(\n",
    "            img=image_size,\n",
    "            epochs=num_epochs,\n",
    "            data=\"dataset/data.yaml\",\n",
    "            weights=base_weights, # Use base weights for training (always start from scratch)\n",
    "            batch=batch_size,\n",
    "            name=name,\n",
    "            project=f\"{project}_{mode}/training\"\n",
    "        )\n",
    "\n",
    "        weights = f\"{project}_{mode}/training/{name}/weights/best.pt\" # Weights used to compute most relevant images in the next batch and for testing\n",
    "        test_results = test_yolo(\n",
    "            img=image_size,\n",
    "            data=\"dataset/data.yaml\",\n",
    "            weights=weights, # Weights from the model trained in this batch\n",
    "            project=f\"{project}_{mode}/testing\"\n",
    "        )\n",
    "        mAP_test = float(test_results.results_dict[\"metrics/mAP50(B)\"])\n",
    "        mAP = float(results.results_dict[\"metrics/mAP50(B)\"])\n",
    "        #results_df.loc[batch, f\"{mode}_mAP\"] = mAP\n",
    "        results_df.loc[batch, f\"{mode} mAP (test)\"] = mAP_test\n",
    "        print(f\"✅ Batch {batch + 1} ({mode}) done — mAP@50: {mAP:.4f}\")\n",
    "\n",
    "# Run both modes\n",
    "run_training_loop(mode=\"al\")\n",
    "run_training_loop(mode=\"random\")\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "# View combined results\n",
    "display(results_df)\n",
    "%matplotlib inline\n",
    "results_df.plot(\n",
    "    y=[\"al mAP (test)\", \"random mAP (test)\"],\n",
    "    marker='o',\n",
    "    title=\"Active Learning vs Random Selection (mAP@50)\"\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel(\"# images\")\n",
    "plt.ylabel(\"mAP (test set)\")\n",
    "plt.xticks(ticks=results_df.index, labels=[int((i+1)*(batch_train_prop+batch_val_prop)*dataset_size) for i in results_df.index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9080c338",
   "metadata": {},
   "source": [
    "## 🧹 Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd8bedf",
   "metadata": {},
   "source": [
    "In object detection, **annotation quality** plays a critical role in model performance.\n",
    "\n",
    "Unlike classification tasks, object detection requires:\n",
    "- The correct **label** for each object\n",
    "- A precise **bounding box** tightly enclosing the object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c259abf",
   "metadata": {},
   "source": [
    "### Common Annotation Issues\n",
    "\n",
    "- **Incorrect Labels**: The object is mislabeled or assigned the wrong class.\n",
    "- **Poor Bounding Boxes**:\n",
    "  - Boxes do not align with the object\n",
    "  - Boxes are too loose or too tight\n",
    "  - Boxes include multiple objects\n",
    "- **Inconsistent Annotations** across similar samples\n",
    "\n",
    "Such errors often stem from:\n",
    "- **Repetitive labeling** tasks\n",
    "- **Fatigue** or insufficient training of annotators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e8398c",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/data_quality.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9377da",
   "metadata": {},
   "source": [
    "### Annotation Quality Example: Original vs Improved Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e038459",
   "metadata": {},
   "source": [
    "As an illustration of the importance of annotation quality, this notebook includes **two versions of the same dataset**:\n",
    "\n",
    "- `dataset/original/`: Contains the original annotations\n",
    "- `dataset/improved/`: Contains refined, higher-quality annotations\n",
    "\n",
    "Both versions share the **same images**, but differ in the accuracy and consistency of their bounding boxes and labels.\n",
    "\n",
    "This allows us to analyze:\n",
    "- How labeling precision impacts training performance\n",
    "- Whether better annotations lead to **higher mAP** and more reliable predictions\n",
    "\n",
    "By training the same model on each version, we can measure how much improvement is achieved **purely through better annotations** — without changing the model architecture or training strategy.\n",
    "\n",
    "> This is especially useful in real-world projects, where annotation time is expensive, and correcting label errors can be more effective than adding more data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041edc76",
   "metadata": {},
   "source": [
    "#### Experimentation Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840a09f2",
   "metadata": {},
   "source": [
    "In this experiment, **two models are trained using the same set of images**, but with **different annotations**.  \n",
    "This setup is designed to evaluate the impact of **annotation quality** on the performance of an object detection model.\n",
    "\n",
    "- Both models share the **same training and validation splits**, ensuring a fair and controlled comparison.\n",
    "- The only difference lies in the annotations:\n",
    "  - One model uses the **original** annotation set.\n",
    "  - The other uses a set of **improved** annotations.\n",
    "\n",
    "---\n",
    "\n",
    "At the end of training, we compare the models using the **mAP@50 metric** to assess how annotation quality affects detection performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9607d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_split, split_dataset, train_yolo, test_yolo\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Get train/val split from dataset (test already fixed)\n",
    "train_split, val_split = get_split(\n",
    "    train_size=0.6,\n",
    "    val_size=0.2,\n",
    "    dataset_size=200\n",
    ")\n",
    "\n",
    "image_size = 608 # Image size for training\n",
    "num_epochs = 5 # Number of epochs for training\n",
    "batch_size = 4 # Batch size for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef67c7c",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "286bc7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "---\n",
       "### **Annotation Quality Comparison**\n",
       "\n",
       "- <span style=\"color:crimson\"><b>mAP with original annotations:</b></span> <code>0.3325</code>\n",
       "- <span style=\"color:seagreen\"><b>mAP with improved annotations:</b></span> <code>0.3465</code>\n",
       "\n",
       "**Absolute improvement:** <b style=\"color:royalblue\">0.0140 mAP@50</b>  \n",
       "**Relative improvement:** <b style=\"color:royalblue\">4.22%</b>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_and_test_yolo(name):\n",
    "    # Train and test YOLO model with original annotations\n",
    "    train_yolo(\n",
    "        img=image_size,\n",
    "        epochs=num_epochs,\n",
    "        data=\"dataset/data.yaml\",\n",
    "        weights=\"yolo11n.pt\",\n",
    "        batch=batch_size,\n",
    "        name=name,\n",
    "        project=\"example_data_quality/train\"\n",
    "    )\n",
    "    \n",
    "    map_results = test_yolo(\n",
    "        img=image_size,\n",
    "        data=\"dataset/data.yaml\",\n",
    "        weights=f\"example_data_quality/train/{name}/weights/best.pt\",\n",
    "        project=\"example_data_quality/test\"\n",
    "    )\n",
    "    \n",
    "    return float(map_results.results_dict[\"metrics/mAP50(B)\"])\n",
    "\n",
    "#---------- Original Annotations ----------\n",
    "\n",
    "# Preparing the dataset with the original annotaions\n",
    "split_dataset(train_split=train_split, val_split=val_split, dataset=\"original\") \n",
    "# Train and test the model with original annotations\n",
    "map_original = train_and_test_yolo(\"original\")\n",
    "\n",
    "#---------- Improved Annotations ----------\n",
    "\n",
    "# Preparing the dataset with the improved annotaions\n",
    "split_dataset(train_split=train_split, val_split=val_split, dataset=\"improved\") # Preparing the dataset with the improved annotaions\n",
    "# Train and test the model with improved annotations\n",
    "map_improved = train_and_test_yolo(\"improved\") # Train and test the model with improved annotations\n",
    "\n",
    "#--------- Calculate improvement ---------\n",
    "\n",
    "# Calculate the absolute and relative improvement in mAP\n",
    "improvement = map_improved - map_original\n",
    "# Calculate the percentage improvement\n",
    "percent_improvement = (improvement / map_original) * 100 if map_original > 0 else float('inf')  # Avoid division by zero\n",
    "# Clear training outputs\n",
    "clear_output(wait=True)\n",
    "# Display the results in a Markdown format\n",
    "display(Markdown(f\"\"\"\n",
    "---\n",
    "### **Annotation Quality Comparison**\n",
    "\n",
    "- <span style=\"color:crimson\"><b>mAP with original annotations:</b></span> <code>{map_original:.4f}</code>\n",
    "- <span style=\"color:seagreen\"><b>mAP with improved annotations:</b></span> <code>{map_improved:.4f}</code>\n",
    "\n",
    "**Absolute improvement:** <b style=\"color:royalblue\">{improvement:.4f} mAP@50</b>  \n",
    "**Relative improvement:** <b style=\"color:royalblue\">{percent_improvement:.2f}%</b>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e37783",
   "metadata": {},
   "source": [
    "## 🧠 Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d691bca",
   "metadata": {},
   "source": [
    "Training object detection models from scratch can be time-consuming and data-hungry. To overcome this, we use **Transfer Learning (TL)** — a technique that leverages a model pre-trained on a large dataset (e.g., COCO) and adapts it to our custom task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca0af0",
   "metadata": {},
   "source": [
    "#### What Can Change?\n",
    "\n",
    "- The model’s **detection head** (final layers) is updated to match the number of classes in our current dataset.\n",
    "- During training, the model retains the **general visual features** it has already learned (e.g., shapes, textures), while adapting to our specific setting.\n",
    "\n",
    "> Transfer Learning helps us build accurate models faster, even with relatively small datasets — by reusing knowledge from related tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce52a4d",
   "metadata": {},
   "source": [
    "\n",
    "#### Why Use Transfer Learning?\n",
    "\n",
    "- **Jump-start training** with already-learned features\n",
    "- **Reduce training time**\n",
    "- **Improve performance**, especially when labeled data is limited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d28ebcd",
   "metadata": {},
   "source": [
    "### Reusing a YOLOv5 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669ad421",
   "metadata": {},
   "source": [
    "#### Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeed2f7",
   "metadata": {},
   "source": [
    "In this tutorial, we leverage **Transfer Learning** by starting from a pre-trained **YOLOv5** model trained to detect **whiteflies in yellow sticky traps**:\n",
    "\n",
    "`pre-trained/yellow_trap.pt`\n",
    "\n",
    "Although the original model was trained on the **same task** (whitefly detection), it was collected in a **different environment**. This makes it an excellent candidate for fine-tuning on our custom data.\n",
    "\n",
    "##### YOLOv5 pre-trained on:\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/tl_v5.png)\n",
    "\n",
    "##### New Dataset\n",
    "\n",
    "![](https://raw.githubusercontent.com/dinisdcosta/IbPRIA2025---Data-Efficient-Strategies-for-Object-Detection/main/images/tl_new.png)\n",
    "\n",
    "As seen in the images above, both scenarios contain **whiteflies**, but in different environments.  \n",
    "A model trained on one of these image sets can be used as a **starting point** for training on the other, leveraging the benefits of **transfer learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740e666",
   "metadata": {},
   "source": [
    "> Recent YOLO models (version 8 and above) are available through the **Ultralytics Python library**.  \n",
    "> However, in this tutorial, we use a **pre-trained YOLOv5 model**, which is **not included** in the `ultralytics` package.\n",
    "\n",
    "> Therefore, we need to **clone the YOLOv5 repository manually** to access its training and inference utilities.\n",
    "\n",
    "> **Note:** The YOLOv5 repository is no longer actively maintained and may produce several warnings during training due to updates in related packages.  \n",
    "> Despite this, it remains **fully functional** and suitable for our fine-tuning task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a43a4ed",
   "metadata": {},
   "source": [
    "#### Cloning YOLOv5 github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f96458",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f374e",
   "metadata": {},
   "source": [
    "#### Experience Preparation\n",
    "\n",
    "In this transfer learning experiment, we train **two distinct models** for comparison:\n",
    "\n",
    "- **Model A:** Starts training using the weights of a **pre-trained YOLOv5** model  \n",
    "- **Model B:** Trains **from scratch** using **YOLOv11n**, with no prior learning\n",
    "\n",
    "Both models are trained using the **same dataset**, including:\n",
    "\n",
    "- Identical **training and validation splits**\n",
    "- Same **number of epochs**, **image size**, and **batch size**\n",
    "\n",
    "---\n",
    "\n",
    "At the end of training, a plot is displayed showing the **evolution of performance (mAP@50)** across epochs for both models, allowing us to visualize and compare their learning behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4180ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_split, split_dataset, train_yolo, train_yolov5\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get train/val split from dataset (test already fixed 20%)\n",
    "train_split, val_split = get_split(\n",
    "    train_size=0.6, # 60 percent of the dataset for training\n",
    "    val_size=0.2, # 20 percent of the dataset for validation\n",
    "    dataset_size=200\n",
    ")\n",
    "\n",
    "# Images to be used for training and validation will be available in dataset/run\n",
    "split_dataset(train_split=train_split, val_split=val_split, dataset=\"improved\")\n",
    "\n",
    "num_epochs = 5 # Number of epochs for training\n",
    "batch_size = 4 # Batch size for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325500af",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc7b96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully. Results saved in 'example_transfer_learning/train/transfer_learning' and 'example_transfer_learning/train/baseline'.\n"
     ]
    }
   ],
   "source": [
    "# Train YOLOv5 with transfer learning using pre-trained weights\n",
    "train_yolov5(\n",
    "    img=1280, # pre-trained/yellow_trap.pt was trained on 1280x1280 images, so we use the same size\n",
    "    epochs=num_epochs,\n",
    "    data=\"dataset/data_yolov5.yaml\",\n",
    "    weights=\"pre-trained/yellow_trap.pt\",  # Using YOLOv5 small as the pre-trained model\n",
    "    batch=batch_size,\n",
    "    name=\"transfer_learning\",\n",
    "    project=\"example_transfer_learning\"\n",
    ")\n",
    "\n",
    "# Train YOLOv11 from scratch on the same dataset\n",
    "train_yolo(\n",
    "    img=1280,\n",
    "    epochs=num_epochs,\n",
    "    data=\"dataset/data.yaml\",\n",
    "    weights=\"yolo11n.yaml\",\n",
    "    batch=batch_size,\n",
    "    name=\"baseline\",\n",
    "    project=\"example_transfer_learning/train\"\n",
    ")\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"Training completed successfully. Results saved in 'example_transfer_learning/train/transfer_learning' and 'example_transfer_learning/train/baseline'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e298b1",
   "metadata": {},
   "source": [
    "#### Plot Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd207f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"example_transfer_learning/train/transfer_learning/results.csv\")\n",
    "df2 = pd.read_csv(\"example_transfer_learning/train/baseline/results.csv\")\n",
    "\n",
    "# Strip leading/trailing whitespace from column names\n",
    "df1.columns = df1.columns.str.strip()\n",
    "df2.columns = df2.columns.str.strip()\n",
    "\n",
    "%matplotlib inline\n",
    "# Plotting mAP@0.5\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df1['metrics/mAP_0.5'], label='Transfer Learning', marker='o')\n",
    "plt.plot(df2['metrics/mAP50(B)'], label='Baseline', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('mAP@0.5')\n",
    "plt.title('Comparison of mAP@0.5 Across Experiments')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
